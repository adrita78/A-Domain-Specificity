{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa8RpDO2WFCh",
        "outputId": "d6d73681-c962-440e-9571-4767b21ff927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device:\",device)\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummaryX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc9bcrxBWV-P",
        "outputId": "2d2729b6-95cd-490f-f0c3-244b45229316"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummaryX in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsummaryX) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryX) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryX) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchsummaryX) (16.0.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->torchsummaryX) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchsummaryX) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchsummaryX) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummaryX import summary"
      ],
      "metadata": {
        "id": "e0W7kddZWYOo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdomainDataset(Dataset):\n",
        "    def __init__(self, filename, padding_token='X', missing_token='-'):\n",
        "        sequences, labels = self.load_file(filename)\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "        self.padding_token = padding_token\n",
        "        self.missing_token = missing_token\n",
        "        self.label_map = self.build_label_map(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.sequences[index]\n",
        "        label = self.labels[index]\n",
        "        return sequence, label\n",
        "\n",
        "    def load_file(self, filename):\n",
        "        sequences = []\n",
        "        labels = []\n",
        "        with open(filename, 'r') as file:\n",
        "            for line in file:\n",
        "                sequence, label = line.strip().split('\\t')\n",
        "                sequences.append(sequence)\n",
        "                labels.append(label)\n",
        "        return sequences, labels\n",
        "\n",
        "    def collate_fn(self,batch):\n",
        "      sequences, labels = zip(*batch)\n",
        "\n",
        "    # Converting sequences to numerical representation (one-hot encoding)\n",
        "      char_to_index = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11,\n",
        "                     'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19, '-': 20, 'X':21}\n",
        "\n",
        "    \n",
        "      numerical_labels = [self.label_map[label] for label in labels]\n",
        "\n",
        "    # Padding sequences to a fixed length and handle missing amino acids\n",
        "      num_chars = len(char_to_index)\n",
        "      encoded_sequences = [[char_to_index[char] if char in char_to_index else char_to_index[self.missing_token] for char in sequence] for sequence in sequences]\n",
        "      padded_sequences = torch.nn.utils.rnn.pad_sequence([torch.tensor(encoded_sequence) for encoded_sequence in encoded_sequences], batch_first=True, padding_value=char_to_index[self.padding_token])\n",
        "      padded_sequences = torch.nn.functional.one_hot(padded_sequences, num_classes=num_chars)\n",
        "\n",
        "      numerical_labels = torch.tensor(numerical_labels)\n",
        "\n",
        "      return padded_sequences, numerical_labels\n",
        "\n",
        "\n",
        "    def build_label_map(self, labels):\n",
        "      unique_labels = sorted(set(labels))\n",
        "      label_map = {label: index for index, label in enumerate(unique_labels)}\n",
        "      return label_map  "
      ],
      "metadata": {
        "id": "FGey-iI2Wgag"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the file path for the dataset\n",
        "filename = '/content/a_domains.tsv'\n",
        "\n",
        "# Create an instance of the AdomainDataset\n",
        "dataset = AdomainDataset(filename)\n",
        "\n",
        "## Split the dataset into train, val, and test sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_dataset,\n",
        "    collate_fn= dataset.collate_fn, \n",
        "    num_workers = 4,\n",
        "    batch_size  = 32, \n",
        "    pin_memory  = True,\n",
        "    shuffle     = True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_dataset, \n",
        "    collate_fn = dataset.collate_fn,\n",
        "    num_workers = 2,\n",
        "    batch_size  = 32,\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = test_dataset,\n",
        "    collate_fn =  dataset.collate_fn,\n",
        "    num_workers = 2, \n",
        "    batch_size  = 32, \n",
        "    pin_memory  = True, \n",
        "    shuffle     = False\n",
        ")\n"
      ],
      "metadata": {
        "id": "qsFFogDSXDs4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/a_domains.tsv'\n",
        "dataset = AdomainDataset(filename)\n",
        "\n",
        "# Iterating through the dataset\n",
        "for sequence, label in dataset:\n",
        "    print(sequence, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83PkH_PI3cPs",
        "outputId": "93817eeb-be7e-4f75-fcae-85efbc13e314"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence amino_acid\n",
            "LFTTFDVCYQESSLITAGEHNHYGPSETHVVTTC pro\n",
            "SWNLFDAFALTTVFMLGGEMNAYGPTESSVMATY phe\n",
            "LVFAFDASVWDGTLITAGSVNGYGPTESTVCATL phe\n",
            "YWASFDLTVTSTKLIVGGEFNEYGPTETVVGCMI asn\n",
            "HWMTFDASVWELQMFCGGEINLYGPTETTIDATY gln\n",
            "NWKLFDAFVLSTTGTLGGEVNEYGPTESSVVATW tyr\n",
            "LHTGFDAMTFEGWLIVGGEWNGYGPTENTTFSTC val\n",
            "VAWAFDVSTGDREAILGADINSYGVTEACIDTSY orn\n",
            "CWRFFDGFVASAYGTLGGENNEYGPTENSVVTTI leu\n",
            "LNSGFDAVTFEGFLYVGGEHNIYGPTENTTFSTF ile\n",
            "VNTSFDGSVFDGFILFGGEIHVYGPTESTVYATY ile\n",
            "TDISFDLSVYDGNSLLSGDISLGGATEGSIWSIY cys\n",
            "LWHAFDAFVWEPFLLTGGDVNNYGPTENTVVATS leu\n",
            "LGLAFDASVKQADMIVGGDTNVYGPTECCVDAAS glu\n",
            "YAFVFDAFSEEPSCISGGDYNSYGPTEATVCATY lys\n",
            "ATWAFDVFAGDRESIMGSDINSYGVTEASVDSGY orn\n",
            "VNTSFDGSVFDGFIFLGGEIHVYGPTESTVYATY ile\n",
            "LAVAFDASAFEPTLVSAGSINAYGPTETTVCATA phe\n",
            "YWFSFDLGYTSSKLVLGGEMNHYGPTETTIGSVF asp\n",
            "YAVSADLGNTTAKIILGGEFNHYGPTETTIGVMV asp\n",
            "YWASFDLTVTSTKLIVGGEYNEYGPTETVVGCMI asn\n",
            "LFFAFDASVWEMTLITAGSINAYGPTETSICATI phe\n",
            "LFFAFDASVWEMTLITAGSINAYGPTETTICATT phe\n",
            "LFTTFDVCYQESSFITAGEHNHYGPSETHVVTTY pro\n",
            "LNTGFDALTFEGWLIVGGDWNGYGPTENTTFSTC val\n",
            "VAWAFDVSAGDREAIVGSDVNSYGVTEACIDSSY orn\n",
            "FGMTFDASVWQWHFFAGGEIHGYGPTEATVDAAF glu\n",
            "AAWAFDVFSGDRESILGSDINSYGVTEATIDSSF orn\n",
            "TWRFFDGCVTSTIITFAGEANEYGPTENSVATTI tyr\n",
            "LHQHFDFSVWEGNQIFGGEINMYGITETTVHVTF thr\n",
            "LFEAFDVCYQESFLIAAGEHNHYGPSETHVVSTY pro\n",
            "FSLTFDASIWEWHFFSGGETNSYGPTEATVEAAF gln\n",
            "TWRFFDGFITSTIITLAGEANEYGPTENSVATTV tyr\n",
            "LALTFDVSVSEMSMIVGGEFNCYGPTEATVCSTM trp\n",
            "LWHAFDASVWEPFLLTGGDVNQYGPTENTVVATA leu\n",
            "MAYTFDVSVSEQSMEVGGDFNCYGPTEATVGTVI trp\n",
            "FWATFDLSVYEANTNLCGEFNLYGPTEDTVYSTH gly\n",
            "LKTSFDAATFEGWLLVGGDINGYGPTENTTFTCC val\n",
            "LNTSFDAATFEGWLLVGGDINGYGPTENTTFTCC val\n",
            "LWHAFDASVWEPFLLTGGDANQYGPTENAVVATA leu\n",
            "LWHAFDAAVWEPFLLTGGDVNQYGPTENAVVATA leu\n",
            "FWATFDLSVYEVNTNLAGEFNLYGPSEDTTYSTY ala\n",
            "LETSFDAATFEGWLLVGGDINGYGPTENTTFTCC val\n",
            "VGMTFDISVAEGNFLACGEENIYGPTEATIYASR gly\n",
            "RWMTFDVSVWEWHFFASGEINLYGPTEATIDVSY ser\n",
            "YWASFDLTVTSTKLIVGGDFNEYGPTETVVGCMI asn\n",
            "SWKYFDAFILNGSTVVGGENNEYGPTENSVVSTF tyr\n",
            "YWASFDLTVTSTKLIVGGECNEYGPTETVVGCML asn\n",
            "LGLAFDASVQQADGLIGGETNVYGPTETCVDASL gln\n",
            "LYEAFDVCYQESFLITAGEHNHYGPSETHVVTMC pro\n",
            "FWIAFDLSVMDPVSLFCGEYNTYGPTEATVAVTQ ala\n",
            "FWAAFDLSVMDPTSLFCGEMNTYGPTEATVAVTG ala\n",
            "YWMSHDPIQRDTHLFFVGDVNMYGTTETQRAVSY aad\n",
            "YTFSFDILVEEPTTISGGEANGYGPSETTVAATF glu\n",
            "NGHH--HGISCRYGMFGGSISHYGSTETLMMSTR aad\n",
            "TAISPDNLVLSPLLYFGGAITALGSTETSIIPSI aad\n",
            "FWMPFDLSVMYPTSYFDGEINAYGPTEATVALSA ala\n",
            "FWMAFDLSIFSPISIFCGEYNTYGPTEATGAISS ala\n",
            "FWMAFDLSVMDTTSLFCGEYNLYGPTETTVAVSY ala\n",
            "YWMSHDPIQRDTHLFFVGDVNMYGTTETQRSVSF aad\n",
            "YWVAFDNSILDSFWLFCGEANLYGPTEITDVCSF glu\n",
            "NEILHDLGIGPHAAMNGAEVPCYGMAEVTLCASA phe\n",
            "YWMSHDPIQRDTHLFFVGDVNMYGTTETQRSVSY aad\n",
            "RWMTFDVSVWELHFYCSGEHNLYGPTEASIDVSA phe\n",
            "FWMAFDLSVMAPVSFFCGEYNTYGPTEATVAVTS ala\n",
            "FWAAFDLSVMDPTSLFCGEMNTYGPTEATVAVTS ala\n",
            "YWMSHDPIQRDTHLFFVGDVNMYGTTETQRAVSF aad\n",
            "FWIAFDLSVMDPTSMFCGEFNTYGPTETTVAVTS ala\n",
            "FWLAFDLSVYEGVSLFCGELNTYGPTEATVATTI ala\n",
            "IAWAFDVCSGDREFICGSDINSYGTTETTIDSTY glu\n",
            "LWYAFDMGMFDPASVVGGELNGYGPSEATCATHL ala\n",
            "FWLIFDVSLFEMVSVFCGETNTYGPTECTVAVTS ala\n",
            "FWTAFDLSVMDPTSLFCGEMNTYGPTEATVAVTG ala\n",
            "FWMSHDPIQRDTHLFFVGDINMYGTTETQRAVSY aad\n",
            "NSIIFTTTGHISSGIMGGACSGFGMTELCGLMYK aad\n",
            "QLLP-----FADFGTSAGAWTPYGATECLPVAAI phe\n",
            "FWMAFDLSVMDPTSLFCGEYNLYGPTETTVAVSY ala\n",
            "FWIAFDLSVTSPVSVFIGEINGYGPTEATVAVSI ala\n",
            "TDISFDLSVYDGNSLVSGDIALGGATEASIWSNY glu\n",
            "FAAAFDVAAEEPDLIIGGEINAYGPTETTVEATV aad\n",
            "LATHFDFSVWEGNQIFGGEVNMYGITETTVHVTY thr\n",
            "AAWAFDVFSGDREFIVGSDINSYGVTEATIDSSY val\n",
            "TDISFDLSVYDGNSMMSGDISLGGATEASIWSIF glu\n",
            "FICIFDFSFEEPYCIVGGELNTYGPTETTITALW phe\n",
            "HAIPCDTFIESPNIMVGGELNAYGALETTLTATV orn\n",
            "LETSFDASTFEGWLLAGGDINGYGPTESTTFTCC phe\n",
            "LETAFDASTFEGWLLAGGDINGYGPTENTTFTCC phe\n",
            "SARSFDSSVAGWLSIVAGEFNEYGPTEGTVWSSV phe\n",
            "YGISADLGNTGAKIILGGEFNHYGPTEATVGVTT phe\n",
            "YWCSFDLTITSSKIIIGGEVNEYGPTETVVGCCI glu\n",
            "YWCSFDLTITSSKLIIGGEVNEYGPTETVVGCCI phe\n",
            "NVTLHDMGIGGQGGFNGAEYPCYGMAEATLMVSG phe\n",
            "QWRIFDPSVWQWALTCGGEYNCYGPTEASIDTTF phe\n",
            "FGVSWDALTLEPFLMFGGEIHVYGPSECTVFTSS asp\n",
            "LAWGFDLSIGETFLTVGGEFNCYGPTESTVNAAL orn\n",
            "FWMAFDLSVTSPVSVFVGEINGYGPTEATVAVSI ala\n",
            "YASSADLGNTTGKIVLGGECNHYGPTETTVGILF phe\n",
            "YWNPFDLSVMDPVSLFCGEYNTYGPTETTVAVTG ala\n",
            "FWMAFDLSVMDPTSLFCGEFNTYGPTEATVAITS ala\n",
            "TQTTHDMSVFDASSAQGGDFSLGGPTETTIWSIW glu\n",
            "SAHAFDVSVFEFELLTIGEYGMYGPTEATIHCTA aad\n",
            "NTLCFDVSVFEFSLVTAGEYQGYGPCETTNICTV cys\n",
            "AAFAFDVSVLEWDLITGGEYNGYGPTEVTIGCTM val\n",
            "NFLV---FIWERLMWFNGELNCYSACETHEIACG aad\n",
            "YWMSHDPIQRDTHLFFVGDINMYGTTETQRAVSY aad\n",
            "SAHAFDAAIQEAGLVLFGELNGYGPTECSIFSSV aad\n",
            "GGHGFDITIQESGLTLFGEINVYGPSECTIHSVC cys\n",
            "SGHAFDVSIQESGLVLFGELSSYGPSECSMHSTC val\n",
            "SPRAFDVSIDSLGIGLGGEIIGYGPCECTIGCTV phe\n",
            "SCIAWDVSIGEGWLLSVGEINGWGPCEASILSTI phe\n",
            "YAFSFDIFVEEASGISGGDYNTYGPSETTVCASY orn\n",
            "KWMTFSPSLWEGGVSCSGEFNDYGSTENAVGYSE glu\n",
            "RWMTFIDHLQEGIAVLSGELNLYGTTEVSGDCTY phe\n",
            "HVASFDGFVEQPDLQATGELNSYGPTETVVTAVT phe\n",
            "SARAFDISVAQALAIVGGDFNEYGPTEATIFSTA phe\n",
            "LGSHFDFSVWEGNQIFGGEVNMYGITETTVHVTY thr\n",
            "YGVSADLGHTTGKIVLGGEINHYGPTETTVGILT phe\n",
            "FWMPFDLSVMSPVSLFCGEFNTYGPTEATVAMTQ ala\n",
            "FWMPFDLSNMYPVSLFCGEFNTYGPTEAAVAITS ala\n",
            "FWLAFDLSVMSPVSLFCGEYNTYGPTEATVAISA ala\n",
            "FWMPFDLSNMYPVGLFCGEFNTYGPTETTVAVSG ala\n",
            "LFFAFDASVWEMTLITAGSVNAYGPTETSICATI phe\n",
            "YFASFDLTITTAKLVVGGEYNEYGPTEATVGCMI ala\n",
            "FWEAFDLSVMSPVSLFCGEFNTYGPTETTVAVTQ ala\n",
            "FWMAFDLSVMDPVSMFCGEFNTYGPTEATVAVTQ ala\n",
            "FWMPFDLSVMDPVSLFCGEFNTYGPTETTVAVTQ ala\n",
            "FWVPFDLSNMYPVGMFCGEFNTYGPTETTVAISG ala\n",
            "FWTAFDLSVFSPVSLFCGEYNTYGPTEATVAISS ala\n",
            "YWNPFDLSVMDPVSLFCGEYNTYGPTEATVAVTG ala\n",
            "FWMPFDLSVMDPVSLFCGEYNTYGPTEATVAVSS ala\n",
            "FWMAFDLSVMAPVSFFCGEYNTYGPTEATVAVTG ala\n",
            "FWEAFDLSVMSPVSLFCGEFNTYGPTEATVAVTQ ala\n",
            "YWMSHDPVQRDTHLFFVGDVNMYGTTETQRAVSY aad\n",
            "FWIAFDLSVTSPVSVFVGEINGYGPTEATVAVSI ala\n",
            "FTFSFDAFVFEVFIYFGGEVHVYGPTETTVFCLK glu\n",
            "FWMPFDLSNMFPVGLFCGEFNTYGPTEATVAVSG ala\n",
            "YWLAFDMAVSVAKLILGGEYNEYGPTEATVAVSV phe\n",
            "FWMPFDLSVSQPVSLFIGEINGYGPTEATVGISH ala\n",
            "NWRYFDPSVWAWGALSGGEANLYGPTEATIDATV aad\n",
            "CAFTFDISLMELQALCGGEWNLYGPTETTIWSTA phe\n",
            "RWATFDVSVWELHFLCSGEHNLYGPTEAAIDVTS phe\n",
            "LWFTFDPSVEDGNFIFGGESNHYGPSETTVDCLT phe\n",
            "YAATFDLTQTAIKCIVGGEINEYGPTEATVGCCI phe\n",
            "INPCFDVYLFEGIILIGGEINCYGPTESTIMSLI phe\n",
            "LGLSFDASVQQPDCMIGGESNAYGPTECCVQSSS phe\n",
            "HGSTFDVGVHEVHAISAGEYNCYGPTETTVYVSH phe\n",
            "HMMTWDIVLEEPDLLVGTEFNAYAQTETTITATD phe\n",
            "YWATFDATITSLKTVIGGEFNEYGPTETVVGCCV phe\n",
            "LSQAFVAMTIEMMLLLGGEFNAYGSTETSSMVTA phe\n",
            "FAQAFDTSVSDPDVIVGGEINSYGPTETTVTATN aad\n",
            "FVQAFDTSVSDPDMIVGGEINSYGPTETTVIATT cys\n",
            "FAQAFDTSVSDPDLIVGGEINTYGPTETTVIATH val\n",
            "LSMTFDIAGLELQAISGGEWNLYGPTETTIWSTA phe\n",
            "YAYSYIAAIRDIGWCFSGSVNQYGPTEATASCTY ala\n",
            "YAYSYIAAIRDLGWCFSGSVNQYGPTEATASCTY ala\n",
            "FAELFDASCEELSTILGGEWNTYGPTEATVVACA phe\n",
            "LWMAFDLSMYEAVSLFCGELNTYGPTEATVATTW ala\n",
            "SEWLYSAQLYPHSIISVGNYEYYGSSEMGFVTVL glu\n",
            "FWIAFDLSVMDPTSMFCGEFNTYGPTEATVAVTS ala\n",
            "FAELFDASCEELSTIFGGEWNTYGPTEATVVACG phe\n",
            "FWIPFDLSVTTPVSIFIGEINGYGPTEATVGVSV ala\n",
            "FWMPFDLSVMDPVSFFCGEYNTYGPTEATVAVTG ala\n",
            "FAVTFDIAVLELQALVGGEWNMYGPTETTVWSTC phe\n",
            "FWMAFDLSVMDPVSLFCGEFNTYGPTEATVAVTH ala\n",
            "YWMPFDLSVMDPVSLFCGEFNTYGPTETCVAVTQ ala\n",
            "FWATFDLSVFEVNTNLAGEFNLYGPSEDTTYSTF orn\n",
            "LSMTFDLSVPDLQAICGGEWNMYGPTETTVWSTV phe\n",
            "YVAAFSITFFESHASTGGDHVIYGCSEVSCMACS phe\n",
            "RWMTFVDSVWEGVLVTSGELNLYGSSEVSADVTC orn\n",
            "YYIFFDLSVHDVFSLFCGEENLYGPTETTIAITH ala\n",
            "SDLSFEPFVRQMNGILVGELNEYGFTESAFVTAL aad\n",
            "LSLSFDHFVEQDSGDCVGEINGYGPTEVSITTHK cys\n",
            "LALSFDFSVEQLSGTAAGEYNAYGVTETTVYNII val\n",
            "SDLSFEPFVRQMHAILVGELNEYGFTESAFVTAL aad\n",
            "LSLSFDFSLEQLSGTAAGENNAYGITETTVYNII val\n",
            "LSLSFDHFVEQDSGDCVGEINGYGPTEISITTHK cys\n",
            "LALSFDFSIEQLSGTAAGEYNAYGITETTVYNIV val\n",
            "SDLAFEPHLRQINALLVGEVNEYAFTEAAFVTAV aad\n",
            "LSLSFDHFVEQDSGDAIGEINGYGPTEISITSHK cys\n",
            "FQLAFDFSVEQLSGLVAGELNAYGTTETTVYNTV val\n",
            "FWMPFDLSVMYPTSYFDGEVNAYGPTEATVALSA ala\n",
            "RWGTFDVSVPEADFEVAGEFNLYGPTEAAVEVTS asp\n",
            "LWLSFDLSQRSMHCLFGGELHQYGVAECTDVASS phe\n",
            "NDLT---FIHGVLSACGGAVPLWGCSETGIASIH phe\n",
            "MGRFWDGSLLKWVATLAGESNEYGPTETTVSCLA phe\n",
            "VAQAFDASVFEWVLVVAGEFNAYGPTEATIMSNA phe\n",
            "LEIAFDTALVEALSLVGGERNAYGPTETTCSVTL phe\n",
            "YWMSHDPIQRDTHLFFVGDVNM-------LWSLS aad\n",
            "YWMSHDPVQRDTHLFFVGDINMYGTTETQRAVSY aad\n",
            "LWMAFDLSMYEGVSLFCGELNTYGPTEATVATTL ala\n",
            "TDIAFDLSVYDGNSLWSGDFSLGGATEASIWSIE glu\n",
            "TAISFDLSVYDGNSLLSGDHALGGATEAGIWSNV glu\n",
            "HAIQFDGAHEGSYVTVGGEVNGYGPTETVITPTL phe\n",
            "GSVLFDAGLSQTTGANTGGYLMYGLTEA-FRSTY phe\n",
            "GSVLFDAGFSQTTAANTGGFLMYGLTEA-FRSTY phe\n",
            "LWHAFDASFHEAII-------------------V asp\n",
            "HAISSDTTIESPNLMVGGELNAYGSIATTFTATV asp\n",
            "LETSFDASTFEGWLLAGGDINGYGPTENTTFTCC orn\n",
            "LQTAFDASTFEGWLLAGGDINGYGPTENTTFTCC phe\n",
            "RWMTFDISVWEWHFMFSGEANLYGPTEASIDVTC phe\n",
            "HAIAFDVAAEEPNLVVGSERNAYGPTEATITATI orn\n",
            "YWCSFDATITSSKIIIGGEINEYGPTETVVGCCV phe\n",
            "RWMTFDISVWEWHFVFSGEANLYGPTEASIDVTA phe\n",
            "RWMTFDVSVWEWHFICSGEHNLYGPTEAAIDVTF phe\n",
            "HYLMHDYGVEGVQAGNAAEAPAYGLAENTLLVST phe\n",
            "LNTAFDAATFEGFLLFGGELHVYGPTENTTFTSW orn\n",
            "FWVAFDLSLIPAVSVFIGELNSYGPTEATIATTV ala\n",
            "YWMSHDPIQRDTHLFFVGD---------LTCTAH aad\n",
            "NHFSFDPSVVEVQAALGGEFNIYGITEVSSWATF aad\n",
            "FWMAFDLSIFSPISILCGEYNTYGPTEATGAISS ala\n",
            "LWHAFDVAAQESYAAQAGEHNHYGPAETHVMTGI pro\n",
            "VPLAFDAALWELTLVVAGETNAYGPTEAAVCTTI phe\n",
            "YDHWFDAAWQPADTALGGEFNCYGPTETTVEAVV lys\n",
            "LWHTFDVAAQEAYAAQAGEHNHYGPAETHVMTGT pro\n",
            "TAQAFDAAVWESALIVAGDVNAYGLTETTVCATM phe\n",
            "LWHTFDFSVQESFALQGGEHNVYGPAETHAVTTH pip\n",
            "LFEAFDVCYQESVSITAGEHNHYGPSETHVVSAY pro\n",
            "TWRFFDGFLTSTIITLAGEANEYGPTENSVATTA tyr\n",
            "FGMTFDASVWQWHFFAGGEVHGYGPTEATVDAAF glu\n",
            "LNSSFDVVTFEGWLIIGGEWNGYGPTENTTFSTC val\n",
            "LDPSFDASLFETYLLTGGDRNMYGPTEATMCATW leu\n",
            "LAHAFDTIVSEMKAVAAGEINAYGPTETTICATV bht\n",
            "YHCSFDLTITATKALLGGEVNEYGPTEATVGCVE asn\n",
            "LEPAFDISLFEVHLLTGGDRHLYGPTEATLCATW hpg\n",
            "LDPAFDASLVEVHLLTGGDRQLYGPTEITLCATW hpg\n",
            "LAHSFDAIVSEMTVLTGGEIQAYGPTETTICSTM bht\n",
            "LGLAFDASVQQTDGLVGGETNVYGPTETCVDASS gln\n",
            "TNTSFDAFMFDGMILFGGELHMYGPSESTVFTTY leu\n",
            "LWHAFDASVWEPFLLTGGDVNNYGPTENTVVATS leu\n",
            "LNAGFDASTFEGWLIIGGDWNGYGPTENTTFSTC val\n",
            "YWFSFDLGYTSPKLVLGGEINHYGPTETTIGAIA asp\n",
            "VETSFDGFTFDGFVLFGGEIHVYGPTETTVFATF ile\n",
            "LATHFDFSVWEGNQVFGGEVNMYGITETTVHVTH thr\n",
            "LDPSFDASTYEVFLWTGGEVDVYGPTETTTFATH val\n",
            "RWATFDLSVWELHFLCSGEHNLYGPTEAAIDVTA ser\n",
            "RWATFDVSVWELHFLCSGEHNLYGPTEAAIDVTA ser\n",
            "YDANFDLSVEEPHLNVTGDINTYGPTEATVSCTA dab\n",
            "VAWAFDVFSADRDFVCGSDVQAYGVTEASIDSTC arg\n",
            "LDNSFDASTPEGISMCGGEFNGYGPTEGTTCATS phe\n",
            "LATHFDFSVWEGNQVFGGEVNMYGITEITVHATY thr\n",
            "FVLAFDMSIKGSDSLLGGEYNMYGPTECTVDATI asp\n",
            "TALSFDLSVFDGNSLLSGDHVLGGATEAGIWSNL cys\n",
            "TDIAFDLSVYDGNSLWSGDVQPGRRTEAAIWSIE cys\n",
            "YWFAFDVSIAEGHFPIGGEHNFYGPTETVINASR lys\n",
            "LGTHFDFSVWEGNQIFGGEVNMYGITETCVHVSH thr\n",
            "AAWAFDVFSGDRESILGSDINSYGVTEATIDSSY ORN\n",
            "TWRFFDGCVTSTLITFAGEANEYGPTENSVATTI tyr\n",
            "LHQHFDFSVWEGNQIFGGEINMYGITETTVHVTY thr\n",
            "CSSAFDLSLFEAFLCLGGEISGYNPAECCPLGIS ala\n",
            "NPLCFDLLIVELGSMQAGEINAYGPAECSVGALA phe\n",
            "AYMSWDIPVTEVLWVFAGEVQGYGPAECSLISTV pro\n",
            "RWMTFDVSVWEWHFFCSGEHNLYGPTEAAVDVSW ser\n",
            "TAISFDLSVYDGNSMLSGDIAMGGATEASIWSNV cys\n",
            "LSLAFDASVKQADGLIGGETNVYGPTETCVDASV gln\n",
            "TETSFDAFMFDGMIMFGGELHMYGPSESTVFATY leu\n",
            "LWHAFDASIWEPFLLTGGDVNNYGPTENTVVATS leu\n",
            "FSMTFDISALELQALVGGETNLYGPTETTIWSAA gly\n",
            "LATHFDFSVWEGNQIFGGEINMYGITETTVHVSY thr\n",
            "TDISFDLSVYDGNSMLSGDIAMGGATEASIWSNA cys\n",
            "ADLAFEPFMRQINGLLVGEINEYAFTETAFVTAI aad\n",
            "FGLSFDFSVEQLSGLVAGEYNAYGTTETTVYNLV val\n",
            "QVTLFPFGCPGGSVQVGSAQQVFGMAEGLLTFTR pip\n",
            "AAYSFDISIADTVLIFTGEYNVYGPAENTLITTA pro\n",
            "GEHAFDASIGDTGICVAGEINMYGPTEATVACIA ala\n",
            "GCHSFDLSILEAFLGFIGEVNSYGPTEACVLVTA ala\n",
            "LNAGFDAGTFEGWLIIGGDWNGYGPTENTTFSTS val\n",
            "YWFSFDLGYTSPKLVLGGEINHYGPTEATIGAIA asp\n",
            "LHVSFDAFTFDAFALFGGEINCYGPTEGTVFATA leu\n",
            "LQTSFDASIWETLFYVGGDYNAYGPTENTVMSTL leu\n",
            "LQTSFDASVWETLLYIGGDFNAYGPTENTVMSTI leu\n",
            "LNSSFDASSWEAMLFAAGDFNAYGPTENTILSTI val\n",
            "LNSSFDISVQETMFFNVGDYNAYGPTENGMQSTM gly\n",
            "LQSSFDASIWETLFYIGGDYNAYGPTENTVMSTI leu\n",
            "LNSSFDASSWEAMLFAAGDYNAYGPTENTVLSTI val\n",
            "LQNSFDASVWETLLYIGGDYNAYGPTENSVMSTI leu\n",
            "LDSTFDVSLFEAIFYVAGDYNAYGPTENAILSTI ala\n",
            "LNSGFDAVTFEGFLYVGGEYNIYGPTENTTFSTF ile\n",
            "FWATFDLSVFEVNTNLAGEVNLYGPSETTTYSTY phe\n",
            "FTMTFDIAALELQALCGGEWNLYGPTETTVWSCR gly\n",
            "LSTHFDFSVWEGSQVLGGEINMYGITEATVHTTF thr\n",
            "LWQIFDYSVQESYALPGGEHNHYGPAESQLVTGY pip\n",
            "LSTHFDFSVWEGNQVFGGEVNMYGITETTVHVTH thr\n",
            "LDPAFDISLFEVHLLTGGDRHLYGPTETTLCATW hpg\n",
            "LDPAFDASLLEVHLLTGGDRHLYGPTETTLCATW hpg\n",
            "LAQAFDAAISEMTVIVAGEINGYGPTETTVCATM bht\n",
            "LNPAFDASLFEVHLLTGGDRHLYGPTETTLCATW hpg\n",
            "LAQAFDAMVSEMTVVVAGEVNAYGPTEATVCAAM tyr\n",
            "TDISFDLSVYDGNSLLSGDISLGGATEASIWSIG cys\n",
            "VSLAHDPSFRNLHTSCGGEVNVYGSTETCVGVSQ glu\n",
            "LDPAFDASLLEVHLLTGGDRELYGPTEVTLCATW hpg\n",
            "LAQAFDAAVSEMTVVVAGEINAYGPTETTVCATM bht\n",
            "FAMTFDISALELQALVGGETNLYGPTETTIWSTF gly\n",
            "FAMTFDISALELQALVGGETNLYGPTETTIWSTV gly\n",
            "LATHFDFSVWEGNQVFGGEINMYGITETTVHVSY thr\n",
            "LNNSFDASTLDAWMIVGGDLNGYGPTEATTFSTT val\n",
            "FWATFDLAVYEANTNVAGECNLYGPSETTTYSSW ala\n",
            "LDNSFDASSPEGFSECGGEFNGYGPTEATTCATR tyr\n",
            "LNNSFDASTLDAWMIVGGDLNGYGPTEATTFSAT val\n",
            "LGTAFDASTFEGWLLTGGDTICYGPTEGTVFTTA val\n",
            "LWHAFDAMAWEPFLLIGGDINNYGPTEATVVATS leu\n",
            "RWMTFDVSVWEWHFMCSGEHNLYGPTEAAVDVTA ser\n",
            "LNNSFDASTMDGFVLCGGEVHCYGPTETTTYATT ile\n",
            "MWGAFDSSVWEWKFLNGGGHNVYGPTETTVDSTG asp\n",
            "YGVSADLGHTLGKIMLGGEVNHYGPTETTVGILT asp\n",
            "RWMTFDVSVWEWHFVCSGEYNLYGPTEAAIDVTH ser\n",
            "LATHFDFSVWEGNQIFGGEINMYGITETTVHVTY thr\n",
            "RWMTFDVSVWEWHFMCSGEFNLYGPTEAAIDVTH ser\n",
            "LIFLFDGGFWEMAIVVAAERNSYGPTETTVCATM trp\n",
            "TEIAFDLSVYDGNSLLSGDTTLGGATEAAIWSNA cys\n",
            "NRTSFDASVLDWFFFCGGEHNLYGPTETSVDATC leu\n",
            "LVQAFDASIWEMTLVVAGEVNAYGPTESTVCATM phe\n",
            "TDISFDLSVYDGNTLLSGDVSLGGATEASIWSVY cys\n",
            "FGTSFDASVIDFAALTGADINGYGPTEGTCACAA leu\n",
            "LWCTFDLSVFDGNSFLSGDISLGGATEATVWSNW cys\n",
            "LAQAFDATVSEMTVVVAGEINAYGPTEATVCAAM tyr\n",
            "LEPAFDISLFEVHLLTGGDRHLYGPTETTLCATW hpg\n",
            "LDPAFDASLFEAHLLTGGDRHLYGPTETTLCGTW hpg\n",
            "LAQAFDAAISEMTVVVAGEINGYGPTETTVCVTM bht\n",
            "FAMTFDIAGLELQALVGGETQLYGPTETTIWSTI gly\n",
            "FAMTFDIAGLELQALIGGETQLYGPTETTIWSTI gly\n",
            "TYATFDVSVWELTCIVGGEYNAYGPTEVAVETTI arg\n",
            "LDYAFDAAVAEPTLLVAGEINAYGPTEATVAVTA tyr\n",
            "LAHAFDTIVSEMKAVAAGEINAYGPTETTICATM bht\n",
            "YHCSFDLTVTATKALLGGEVNEYGPTEATVGCVE asn\n",
            "YWASFDLTITSTKLIVGGDFNEYGPTETVVGCMI asn\n",
            "YWASFDLTVTSTKLIVGGECNEYGPTETVVGCMI asn\n",
            "LYEAFDVCYQESFLIAAGEHNHYGPSETHVVTMY pro\n",
            "YWASFDLTVTSTKLIVGGEFNEYGPTEAVVGCMI asn\n",
            "TYATFDVSVWESTCIVGGEYNAYGPTEVAVETTI arg\n",
            "LDPAFDASLFEVHLLTGGDRHLYGPTETTLCATW hpg\n",
            "LEPAFDISLFEVHVLTGGDRHLYGPTEVSLCATW hpg\n",
            "LETAFDISLFEVHVLTGGDRHLYGPTEVSLCATW hpg\n",
            "LAQAFDAAVSEMTVVVAGEINAYGPTETTVCASM tyr\n",
            "LESAFDISLFEVHVLTGGDRHLYGPTESTLCATW hpg\n",
            "LDRVFDVSMADPVMVSGGDHNEYGVTEATVVSTV trp\n",
            "SDLSFEPFVRQMNGVLVGELSEYGFTESAFVTAL aad\n",
            "LSLSFDHFVEQDSGDCVGEINGYGPTEVSITTSK cys\n",
            "LSLSFDFSLEQLSGTAAGENNAYGITETSVYNIV val\n",
            "AEIASPLALYEGHSLLGGEAHLSSATPSGPWTTC cys\n",
            "TCVSFDLAVYDGNSLLSGDMSLGGATEASIWSVW cys\n",
            "RWMTFDVSMWEWHFVCSGEYNLYGPTEAAVDVTA ser\n",
            "YWASFDLTVTAAKIVAGGEVNEYGPTETTVGCCA asn\n",
            "LACHFDFSVWEGSQVLGGEVNMYGITENTIHVTV thr\n",
            "FWATFDLSVFEANTNLAGERNLYGPSEATTYATA ala\n",
            "SARSFDSSVAGWLAIAAGEHNEYGPTETTVWSTV asn\n",
            "VQTTHDMSVFDAVSAQGGDISLGGPTETTIWSIW thr\n",
            "LWQAFDVAFQESYMITAGEHNHYGPTESHVVTAL pro\n",
            "LDNSFDASTLDAWLIVGGDLNGYGPTEATTFSTT val\n",
            "TDIAFDLSVYDGNSLWSGDFSLGGATEAAIWSIE cys\n",
            "RWMAFDVSVWEWHFFSGGEHNRYGPTETAINVTH tyr\n",
            "LNTAFDAATFEGFLLFGGELHVYGPTENTTFSSW ile\n",
            "HWMTFDASVWEAQLFCGGEHNLYGPTETCIDATF gln\n",
            "LWQVFDYSVQESYACQGGEHNHYGPAESQLITGY pip\n",
            "LSAAFDVSLLEMLLVMAGEFNGYGPTEATVLATI pro\n",
            "RWGTFDVSVWEWHFFCSGEHNLYGPTEAAIEVTH ser\n",
            "LWHTFDVSAQESFAAQAGEHNHYGPTETHVVTAH pro\n",
            "FAMTFDIAALEHQGLVGGEVNLYGPTETTIWSTA gly\n",
            "LDPSFDASTYEVWLWTGGEVDGYGPTETTTFATH val\n",
            "LAQAFDASISEMTLIVAGEFNAYGPTEASVCATI tyr\n",
            "LWQAFDVSFQETFVITAGEHNHYGPSESHVIITF pro\n",
            "LWHAFDAAVWEPFLLTGGDVNNYGPTENTVVSTS leu\n",
            "FSMTFDIAALELQALCGGEWNLYGPTETTIWSSI gly\n",
            "YWASFDATITSLKIVLGGEINEYGPTEAVVGCCV asn\n",
            "RWMTFDVSVWEWHFICSGEHNLYGPTEAAIDVTY ser\n",
            "LWHAFDVSFQETFLITAGEHNHYGPSESHLATSF pro\n",
            "LWHAFDAAVWEPFLLTGGDVNNYGPTENTVVTTS leu\n",
            "TDMSFDLSVYDGNSLMSGDVSLGGATEASIWSIL cys\n",
            "LNTHFDFAVWEGNQIFGGEVNMYGITETTVHVTH thr\n",
            "LVLHFDASVWENTQAVVGEINAYGPTETTICVTS phe\n",
            "LTLHFDYSVWEGSQVFGGEINMYGITETTVHASF thr\n",
            "LALHFDVSVWEGCQIVAGEINAYGPTEATIYAAM ala\n",
            "TYNTFDVSVWESTCIVGGEYNAYGPTEVAVDATV arg\n",
            "LWHAFDAAVWEPFLLTGGDINNYGPTENSVVTTS leu\n",
            "RWMTFDVSVWEWHFFCSGEHNLYGPTEAAIDVTY ser\n",
            "LWSTFDLSVFELNTNLAGEYNLYGPSEDTTYSTF ala\n",
            "VSLAHDPSIRNLHTSVGGEINVYGSTETCVGVSQ glu\n",
            "TYNTFDVSVWELTCIVGGEYNAYGPTEVAVETTI arg\n",
            "LWHAFDAAVWEPFLLTGGDINNYGPTENTVVTTS leu\n",
            "LWSTFDLSVFELNTNFAGEYNLYGPSEDTTYSTF ala\n",
            "YRASFDLTITATKAILGGEINAYGPTESTVNITD asp\n",
            "FDMTFDIAGLELQALVGGETNLYGPTEATIWATA gly\n",
            "YVSSFDLTVTGAKAVLGGELNEYGPTETIVGCTT asn\n",
            "RWMTFDVSVWEWHFFCSGEHNLYGPTEAAVDVTY ser\n",
            "LATHFDFSVWEGNQVFGGEVNMYGITETTVHVSH thr\n",
            "LIFLFDASFWEMSLVVGAELNSYGPTETTVCSTM trp\n",
            "LDHAFDVSCYEVHLLTGGDRHLYGPTETTLCVTQ hpg\n",
            "FCMTFDIAALELQALCGGEWNMFGPTETTIWSTM gly\n",
            "NAIMHDMGLIAPSSANGAELNVYGLAEASVGATF glu\n",
            "VALAFDGSVVEMQLMVAGELNGYGPTETTVGAAM phe\n",
            "LALSFDGSISEMTLIVTGEVNAYGPTEITVAATA tyr\n",
            "FWMPFDISHFYVFGVFCGEYNTYGPTEATVAVTS ala\n",
            "YGVSADLGHTAGKIVLGGELNHYGPTETTVGVLT asp\n",
            "ASILFGYGLNQSALTAAAAFCMYGQTECTRISFL phe\n",
            "FWLNFDASQYELVSISCGEVNTYGPTECTVAVTA ala\n",
            "TDISFDLSVYDANALLSGDISLGGATECAIWSVY glu\n",
            "CTVTFDISVLELQALCGGEWNVYGPTETTIWSTF phe\n",
            "VCHAFDVAQLESFVFTAGEVDCYGPAEATIFATC aad\n",
            "FVAMFDFSVEEVCVLVSGELNVYGPTEATVTATW phe\n",
            "FWSAFDLSVFDVYSIFAGEYNFYGPTETNVSTYY phe\n",
            "VETTHDMSVFDAVSAQGGDFSLGGPTETTIWSIW phe\n",
            "FWEVFDVSVMSPVSLLCGEFNTYGPTETTVAITQ ala\n",
            "LSFTFDIFFVELQTVLGGEFNGYGPTETTIYVTV phe\n",
            "IHTSFDGFTFDGFVLFGGEIHVYGPTEVTVFATA ile\n",
            "LWMTFDVSLYDGVSLFCGELNTYGPTEATVATTL ala\n",
            "FWSAFDLSVMDTVSLFCGEINTYGPTESTVAVTG ala\n",
            "FWEAFDLSVMDPVSLFCGEFNTYGPTETTVAISG ala\n",
            "RWMTFDVSVWEWHFIVSGEHNLYGPTEAAIDVTH phe\n",
            "YGVAADLGYTAGKIVTGGEFNHYGPTETTVGVIA asp\n",
            "NELSFDPYYIEFQIMFGGEYNLYGITEISCWSFM phe\n",
            "FWEPFDLSVMDPVSLFCGEFNTYGPTEATVAVSA ala\n",
            "FWGAFDLSVMDLVSMFCGEINSYGPTEATVAVTA ala\n",
            "FWIAFDLSVTSPVSIFVGEVNGYGPTEATVAVSA ala\n",
            "YWSAFDLSVMDTVSLFCGEINTYGPTESTVAVTD ala\n",
            "FWAAFDLSVMDPTSLFCGEMNTYGPTEATVAVTA ala\n",
            "YSVSADLGNTMPKIVLGGEFNHYGPTETTVGVLW phe\n",
            "FWIAFDASVPDIVWIFCGEVNMYGPTEATYACMY ala\n",
            "FCFAFDVSVKDSIWMFSGEVNLFGPTEITCNCSY phe\n",
            "MNLAFDASILESTLAVVGEINGYGPTENTVMSTV phe\n",
            "FWYAFDMGIMDPFSFVAGERHAYGPTETTCVTHS ala\n",
            "FWMPFDLSVMDPVSFFCGEYNTYGPTEATVAVTS ala\n",
            "FWIPFDLSVMDPVSLFCGEFNTYGPTETTVAISQ ala\n",
            "FWTTFDLSIFETNTNLAGEYNLYGPSEDTTYSTA phe\n",
            "LWMSFDASVLDPFLLTGGEYNLYGPTECTVLVAF phe\n",
            "FWQPFDLSVMDAVSLFCGEFNTYGPTESTVAVSA ala\n",
            "FRQAFDAAVIDVLLAIGGEINSYGPTETTVAVTN phe\n",
            "FWVAFDLSVMAPVSLFCGEYNTYGPTEATVAITS ala\n",
            "FWAAFDLSVMSPVSLFCGEYNTYGPTEATVAVSQ ala\n",
            "RWMTFDVSVWEWHFFASGEINLYGPTEATVDVSF phe\n",
            "FAELFDASCEELSTILGGEWNTYGPTEATVVATA phe\n",
            "FWMPFDLSVMYPISYFDGEINAYGPTEATVALSA ala\n",
            "FWTAFDLSVMGPISLFCGEYNTYGPTEATVAVSG ala\n",
            "FWMAFDLSIFSPVSIFCGEWNTYGPTEATGAITS ala\n",
            "RWQTFVDSICEGVLVCSGECNFYGSTEIMGDVSY phe\n",
            "FWMPFDLSVMSPVSLFCGEFNTYGPTESTVAITE ala\n",
            "FWKAFDLSVMSPVSLFCGEFNTYGPTETTVAVTQ ala\n",
            "RWMTFDVSVWEWHFICSGEVNLYGPTEAAIDVSC orn\n",
            "LFLSFDGAMKDLLWSFAGEVNLYGPSETTVDCAY ala\n",
            "LSTHFDFSVWEGNQILAGEFNGYGITETTVFVSF phe\n",
            "YWMAFDLSVMAPVSLFCGEFNTYGPTETTVAVTQ ala\n",
            "YAFSFDIFVEEASGISGGDYNTYGPSEITVCASY glu\n",
            "YSKSFDMAIAQILGCSGGEVDCYGPTEISCCATM phe\n",
            "FWAAFDLSVMNPVSVFCGEFNTYGPTEATVAMTS ala\n",
            "YWMAFDLSVMHPTSYFDGEINAYGPTEATVALSA ala\n",
            "YWIAFDLSVMDRVSLFCGEFNTYGPTETTVCVTA ala\n",
            "GIVLFDYGLNQTAGTNSGGYLMYGLTEAFRSTFL phe\n",
            "MTQAFDATVWEMTLVVAGEFNAYGPTESTVCASI phe\n",
            "LNDHFDFSVWEGNQIFGGEINMYGITETTVHVTY thr\n",
            "TQLTFDFSVPECNLFACGEENIYGPTEAAVYATR ala\n",
            "TAYAFDVFVGDRESITSSDINSYGVTEAAIDSSF dab\n",
            "TGYAFDVFVGDRESITSSDINSYGVTEAAIDSSF dab\n",
            "TGYAFDVFVGDRESITSSDINAYGVTEAAIDSSF dab\n",
            "LDQIFDVFVSEMSLIVGGEVNAYGPTETTVEATA trp\n",
            "FYSSFDLTVTSPKALVGGEFNDYGPTEATVNCVD asn\n",
            "YRGHFDLTVTVTKALLGGEINAYGPTELTVNCAE asp\n",
            "LACHFDFSVWEGSQVFGGEVNMYGITETTVHVTV thr\n",
            "FDATFDIAGLEAQALVGGETNVYGPTEATIWATA gly\n",
            "LEQAFDVAVAEMLAVTGGEFNVYGPTEATVQATS trp\n",
            "FRASFDLTVVTGKAVLAGELNSYGPTETTVNCLE glu\n",
            "HRSSFDLTVTATKGVLGGEFNDYGPSETSVNCSD asn\n",
            "LACHFDFSVWEGSQVFGGEVNMYGITETTVHVTH thr\n",
            "RWMTFDVSVWEWHFFSSGEHNLYGPTEAAVDVTW ser\n",
            "LSTHFDVSVWEGNQVFAGEVNMYGITETTVHSSF ser\n",
            "YWHVFDVAVGEPYLLVIGDLNAYGPAEATVAATQ gly\n",
            "IEAYFDGGVWELTLGLAGDFNIYGPSEATLSVAL phe\n",
            "RWMTFDVSLWEWHFLCSGEHNLYGPTEASIDVTA ser\n",
            "YWASFDLTVTTAKVVMGGEFNEYGPTETVVGCAV asn\n",
            "LTTHFDFSVWEGNQIFGGEINMYGITETTVHVTY thr\n",
            "IVSAFDASVWEALLISGGEFNAYGPTETTIYATL leu\n",
            "YWASFDLAVTGVKVVVGGEVNHYGPTETTVGCCV asp\n",
            "LATHFDFSVWEGSQVFGGEVNMYGITETTVHVTH thr\n",
            "YWASFDFTLTNCKLIVGGEYNEYGPTEATVGCIV asn\n",
            "RWMTFDVSVWEWHFVCSGEYNLYGPTEAAVDVTA ser\n",
            "LGHAFDASWDPWDVVVGGEVNLYGPTETTVDAYY arg\n",
            "LATHFDFSVWEGNQVFGGEVNMYGITETTVHVSY thr\n",
            "TDISFDLSVYDGNSLLSGDVSLGGATEASIWSIY cys\n",
            "FSMTFDIAALELQALCGGEWNMFGPTETTIWSAV gly\n",
            "LEPGFDASTLEGWMLVGGDINGYGPTENTTFSTT val\n",
            "RWMTFDVSVWEWHFFFSGEHNLYGPTEAAVDVSF ser\n",
            "LSTHFDFSVWEGNQIFGGEVNMYGITETTVHVSY thr\n",
            "RWMTFDVSVWELHFFTSGEHNLYGPTEAAVDVTY ser\n",
            "LAQAFDASISEMTLIVAGEFNAYGPTEATVCATI tyr\n",
            "TDISFDLSVYDGNSMMSGDISLGGATEGSVWSIL cys\n",
            "VHFTFDISALELQAVCGGELNVYGPSETTIWSTS gly\n",
            "FAMTFDIAGLELQALCGGEWNMYGPTETTIWSSV gly\n",
            "TAITFDISVLEMQALCGGEWNVYGPTEATIWSTI gly\n",
            "AWTSHDFSVYDGSTMLGGDVSVGGPTETSLWNIT thr\n",
            "FSMTFDIAGLELQALCGGEWNMYGPTETTIWSMV gly\n",
            "LSQAFDASASETTIVAAGEVNAYGPTESTIGATF tyr\n",
            "TDISFDLSVFDSNSMMSGDLSLGGATEAAIWSIA cys\n",
            "YWASFDLTVTSTKVIVGGEINEYGPTETVVGCMI asn\n",
            "LWQAFDICYQETYLITAGEHNQYGPSECHVVTSH pip\n",
            "FSMTFDIAGLELQALCGGEWNLYGPTETTIWSTV gly\n",
            "LWHAFDASVWEPFILTGGDVNNYGPTENTVVTTS leu\n",
            "AGWAFDVFAGDREFVVGSDINSYGLSEATIDSTY orn\n",
            "LWQAFDISLQESFVSQAGEHNHYGPSEAHVVTSY pip\n",
            "LHSSFDASVWELVLLSAGDYNGYGPTENGIQSTI phe\n",
            "VSPTFDVSLWETVFFSSGDHNAYGPTENGIQSTI pro\n",
            "LQSSFDASAWEAMLYLGGDINAYGPTENSVISTT leu\n",
            "YAKSFDMGLAQNLACLGGEQDSYGVTEISACTTF trp\n",
            "LSDFFDGATYETIMISGGDYNGYGPTENGVFSTV leu\n",
            "GSYAFDVCMVDTALLLVGEYNVYGPAENNLITTA pip\n",
            "GELAFDASIGDCGICFSGEVNMYGPTEATVACIA ile\n",
            "SSHAFDPSLMEVMAWSMGEVNAYGPTEGAINCTY aad\n",
            "SSLSFDVSIQDYHLTMIGEFNTYGPAEATVVSTI cys\n",
            "FSIAFDPHLLEFSFTVGGEVNAYGPTEVTIGCTF val\n",
            "SAHAFDVSIMESFLVMGGEMNEYGIAECSVASTI trp\n",
            "GSHAFDVSIMESFMIVGGEMNAYGPAECSVNVSV trp\n",
            "SHHSFDVSIYETFLVLGGEINGYGPAEATICGVG pro\n",
            "HLKSFDMSIIQSIACLGGETNCYGPTEITAAATF trp\n",
            "HLKSFDMSLVQCIACMGGETNCYGPTETTAAISF tyr\n",
            "PGVSFDAAVYQITHMVAGEINAYGPTEASICSSL phe\n",
            "HAKSFDMSVVQCIACMGGETNCYGPTEITAAATF tyr\n",
            "QGFSFDFSLEQVSGFFGGEFNNYGPSETTIACTH ser\n",
            "QWLTFDAAQWESQCFSGGEINLYGPTECTINNSA gln\n",
            "LAQAFDACISEMTLIVAGEFNAYGPTEGSVCATL tyr\n",
            "LTQSFDASFWEMTLVVAGEVNAYGPTESTVCATM phe\n",
            "LSHSFDGAFWDMTLVNVGEVNAYGPTESTVSATM trp\n",
            "LSLAFDASVSEGMLEFCGEFNAYGPTEATVCFSL phe\n",
            "RCMAFDVSVWEWHFFSGGKHNRYGPTETAINVTH ser\n",
            "HAVYFDASTE-RGFITGGEFNAYGPTETVVMPLA phe\n",
            "NSKAFDISVWQAESLPTGEVNAYGPAECSDDVAF dab\n",
            "HAVYFDAATERVGFITGGEFNAYGPTETVVMPLA phe\n",
            "LALAFDVFMSDREFTCGADVSVYGVTEATCESAT lys\n",
            "YTLSFDVSVREWHFMTSGERNMYGPTETTVEMTD ser\n",
            "YQVFFDACLGVSPLFLGGEFNCYGPTETTCTSLI tyr\n",
            "LFPLFDCCVNEAMCALAGELNVYSPSECTISTVY ser\n",
            "LDHAFDTSWEGIDVMLGGEYNYYGPTEFTVDALA orn\n",
            "YRGSFDLTVTVTKVLVGGEVNAYGPTELTVNCAE asp\n",
            "FWATFDVSVVEASGALAGEANFYGPTEATVYATA ala\n",
            "FDMTFDIAALEVQAVVGGETNMYGPTETTIWSTS gly\n",
            "RWMTFDVSVWEWHFICSGEHNLYGPTEAAVDVTH ser\n",
            "YRTSFDLTVGAAKATLGGEFNVYGPTETTINCAE glu\n",
            "LWATFDVSVFDVNALCAGEANLYGPTETTVFVTA ala\n",
            "YGASFDLSATATKAVLGGEVNAYGPTELTVNCAE asp\n",
            "LAHSFDASWDPADLALGGEMNTYGPTETAVDAVV lys\n",
            "YGATFDLTVTTTKAILGGEVNAYGPTELTVNCTE asp\n",
            "FDMTFDIAVLEAQALVGGELNLYGPTETTVWSTV gly\n",
            "FRSGFDLTVTTTKVVVGGEFNDYGPTEATVSCAD asn\n",
            "YRGSFDLTVGAVKVTFGGEYNVYGPTETTVNCSE glu\n",
            "LAQAFDGAVLEMFIVVGGELNIYGPTETTAVTLT ile\n",
            "EWMALNASGWEWHVMCSGEHSLYGPVEAMPVVTS cys\n",
            "FSMTFDIAALELQALTGGEINLYGPTETTVWSTL gly\n",
            "LWCTFDLSVFDGNSFFSGDISLGGATEATVWSNF cys\n",
            "LDPAFDASTYEVWLWAGGDVNGYGPTETTTFAAR cys\n",
            "CASSFDISIFEAFLCLGGEVTGYNPAESCPLGIS ala\n",
            "NHLAFDAMIVEIMLVQAGEFNAYGPTECSVISTT val\n",
            "AHLSWDIPVTDLLLVLAGEIQGYGPAECSLVSTV pro\n",
            "SAWAFDLFIGDRDFVCGADLGSYGVTEATIDSSV thr\n",
            "NAMVFDVVLGEPWIIVAGELNGYGPTECAIVVSL lys\n",
            "HMKAFDISLWQAQISVTGEVNAYGATEVSDDTMH asn\n",
            "FTCSFDLTVTVTKAVLGGEFNDYGPTETTVNCAD dab\n",
            "LWHLFDFAVQEQFAFQGGEHNVYGPAETHAVTTA pip\n",
            "YWASFDLTVTATKGMLGGELNVYGATEATVNSVQ asp\n",
            "YRGSFDLTVTATKVVTGGEVNAYGPTEATVNCTD asp\n",
            "FDMTFDIAGLEVQALVGGETNLYGPTETTVWSTV gly\n",
            "LARSFDASTFETFVWAGGDANEYGPTETTVFSTV dab\n",
            "LDSSFDASAYEVWLWTGGDVDGYGPTETTTFAVR val\n",
            "LWHTFDVSVQESYAVQAGEHNHYGPAETHVVTAY pro\n",
            "LHHAFDVSYHEAILITAGEYNFYGPSEADLVTAY pro\n",
            "TAVSFDLGVYDGNSLLSGDIGMGGATEASIWSVW cys\n",
            "LDPSFDASTFEAWLLAGGDVNGYGPTENTTFTCL val\n",
            "YWASFDFTLTAAKLVLGGEFNEYGPTETVVGSTA asn\n",
            "LWCTFDLSVFDGDSFLSGDVSLGGATEATVWSNY cys\n",
            "LDGSFDASTYEVWLWAGGDVNGYGPTETTTFAAR val\n",
            "RWMTFDVSVWEWHFICSGEYNLYGPTEAAVDVTE ser\n",
            "LGMAFDIAALELQAITSGETNLYGPTEATIYSTA gly\n",
            "LSQAFDAAFWDLTLVSTGDLNGYGPTEVTVGISI trp\n",
            "TDIAFDLSVYDGNSLLSGDISLGGATEGSIWSVC cys\n",
            "LRGFFDGATYELIMMVAGDYNAYGPTENGVMSTL phe\n",
            "TWRPFDSSVEDTLATVAGEFNEYGPTENSVCSTR his\n",
            "FGAAFDASVEELDLIIGGELNTYGPTEATVVATT lys\n",
            "MNHVFDMSWEEWNVLLGGEYNLYGPTEYTINTLG hrn\n",
            "RCLTFDTSVWEWDFTVGGEHNLYGPTEAAVDVLG hrn\n",
            "LTAAFDVAVWEMALLVGTEVVAYGLTEATVNSTL han\n",
            "LTAAFDVAVFEMALLVGTEVVAYGLTEATVNSTL han\n",
            "HC-PFDASVMDAHSVLGGELNGLGPTECTTALQY glu\n",
            "NNKAFDVSVWQIEVMVNGEINAYGPTEASDDITH dap\n",
            "LGITFDIFVLELQMMLGGEYNMYGPTETTVWSSI gly\n",
            "RGFSFDASIEELSLIIGGELNTYGPTENTVIATY lys\n",
            "FWATFDLSIFEVNSNLAGECNLYGPSETTTYSAW ala\n",
            "FSTAFDVSVFESDLFVGGEFNGYGPTECTVTMIV val\n",
            "MAWSVDLFFSDLVTMVGSEVNAYGSTETTVDSTV bnd\n",
            "AAWSFDASIMDVVTLLGGEINVYGQTETTVACTM adh\n",
            "LTVAFDVAIWETTLHIGGEINGYGATETTVAATL dmw\n",
            "FTLSVDASVLEWHISVGAEVNAYGPTECTVAASH leu\n",
            "LGHAFDASWDP-DVVVGGEVNLYGPTETTVDAYY arg\n",
            "YWKPFDSSVADPTTTVAGEINEYGPTECSVGATA his\n",
            "TWRPFDSSVADCLITVAGEFNEYGPSENAVCSTV his\n",
            "SARSFDSSVALGLCIVAGEYNEYGPTEGTVWASV his\n",
            "SARSFDSSVAGGLCIVAGEYNEYGPTEATVWATV his\n",
            "HWMTFDASVWEAQLFCGGEHNLYGPTEACIDATF gln\n",
            "LWSTFDASVWEWQFVCGGGHNVYGPTETTVDSSA gln\n",
            "LWSTFDASVWEWQFVCGGGHNVYGPTETTVDCSV gln\n",
            "HWITFDASVWEAQVFAGGEVNLYGPTETTIDATY gln\n",
            "MNHVFDMSWEE-NVLLGGEYNLYGPTEYTINTLG hrn\n",
            "QALAFDMSVEEGNLMIGGEFNAYGPTEATVNASI orn\n",
            "LTVAFDASVIEMMILVGAEVNGYGPTEATIATSF orn\n",
            "LSHWFDASWQP-ELGVGGEYNLYGPTECTVDSAA hrn\n",
            "MTAAFDSSVGEYFISTGGELNAYGPTETTVDATV orn\n",
            "LNHAFDTSWEG-DLMLGGEYNFYGPTEATVDTLW orn\n",
            "LTAAFDVTVWEMALLVGTEVVAYGLTEATVNSTL orn\n",
            "LTAAFDVFVFEMILLVGTEICAYGLTEATVNSTL orn\n",
            "FDMTFDISALELQAFVGGEHNVYGPTETTIWSTA gly\n",
            "FAMTFDIAALELQALCGGEWNLYGPTEATIWSSI gly\n",
            "FSMTFDIAALELQA-IGGEWNMYGPTETTVWSMI gly\n",
            "FGITFDISLLEGQALCGGEWNCYGPTEATVWSLV gly\n",
            "ASFTFDIAMLELQGWCGGEWNLYGPTETTIWSAA gly\n",
            "LWATFDVSVFEPSGALCGEANIYGPTEATVYATA gly\n",
            "FSMTFDIAVLELQALVGGETNLYGPTETTVWSGA gly\n",
            "SRSLFPLSSPGGSLQVGGAQQVFGMAEGLVNYTR gly\n",
            "SARSFDSSVPAWVLICAGEANEYGPTETTVWSSL his\n",
            "LAHAFDASLDP-DLGPGADYNFYGPTECTVDSVV lys\n",
            "QWTYFDPSLLETDLFSGGEFNVYGPTEATVQVTS arg\n",
            "MSLSFDAHLMEPMLAIGGEFNCYGPTEDSVCATV leu\n",
            "MGLAFDAHVFEIILLVGGEFNAYGPTEASVCATM leu\n",
            "LAHAFDVSIADQMIATGGEFNAYGPTEATVTVTL leu\n",
            "LTMAFDTSVWEMTLIVAGEFNSYGPTETTVDATL his\n",
            "CWMAFDVSVWEWNFICGGEQNLYGPTETTIHVTH arg\n",
            "SSYAFDAFVCDTSMTMGGECNVYGPAETAINTTI gln\n",
            "HWMTFDASVWEAQLCVGGEWNLYGPTEATIDALA gln\n",
            "LWSTFDASVWEWQFFCGGGHNVYGPTEATVDSTV gln\n",
            "HWQTFDASVWETQFFSGGEVNLYGPTEATIDSTS gln\n",
            "LWHAFDAMAWEPFLLIGGDVNNYGPTEATIVATS gln\n",
            "YWSSFDATITCTKLVIGGEINEYGPTETVVGCSI gln\n",
            "HWFTFDASVDEAVVFSGGEVNIYGPAETTVESVY gln\n",
            "LGLAFDASVQQ-DCLLGGELNVYGPTECTVDTTS gln\n",
            "ATHAFDAVLQDTNLILAGELNVYGPTECSINSTC gln\n",
            "RRLT-DGSVDGAYSVCRGEHNLYGLIEAGAGITT thr\n",
            "LAMAFDIAVLELQAISTGETNLYGPTEATVYSSA ala\n",
            "SVSLYPMSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SASLFPLSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "GRFVFGASAT-GLGVSGGSISLYGSADGVNCHNA dhb\n",
            "NASLFTLACPGGALQVGGAQQVFGMAEGLLCYTR dhb\n",
            "NASLFPLACPGGALQVGGAQQVFGMAEGLLNYTR dhb\n",
            "SASLFPMSSPGGAAQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SASLYPMSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SRSIYAMSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SASLFTLSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SASLFMLSSPGGSLQVGGAQQVFGMAEGLVNYTR dhb\n",
            "NAVTHNLNMGCGGVVA---HHIFGMTEGVIMFAR dhb\n",
            "SKSLYPLSSPGGAVQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SASLFPLSSPGGALQVGGAQQVFGMAEGLVCYTR dhb\n",
            "SRSLYAMSSPGGSLQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SESLYALSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SESLFPMSSPGGAAQVGGAQQVFGMAEGLVNYTR dhb\n",
            "VETLFPLCCPGGGLQVGGSQQIFGIAEGLIMTTS dhb\n",
            "VYSLFPLGCPGGGLQIGGSQQIFGIAEGLISTTS dhb\n",
            "NCCLFTLGCPGGALQVGGSQQVFGMAEGLICCTR dhb\n",
            "SASLFPMSSPGGSLGVGGAQQVFGMAEGLVNYTR dhb\n",
            "NASLFPLACPGGALQAGGAQQVFGMAEGLLCFTR dhb\n",
            "SRSMFTMSSPGGALWVGGAQQVFGMAEGLVNYTE dhb\n",
            "SRSLFPLSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "NKALYPLANPGGSVLIGAAQQGYGLGEGITCFTQ dhb\n",
            "LELLFALCCPGGALQIGGSLQLYGMSESLITCSR dhb\n",
            "SESLFPLSSPGGGVLVGGAQQVFGMAEGLVCYTR dhb\n",
            "NCCLFTLGCPGGALQVGGSQQVFGMAEGLIACTR dhb\n",
            "SGSLFPLSSPGGALLVGGAQQVFGMAEGLVNYTR dhb\n",
            "SRSLYPLSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "VQCLFPLGCPGGALQVGGAQQVYGIAEGLICMTD dhb\n",
            "SKCMFHICGPGGALQLGGAQQIYGMGEGLVYATY dhb\n",
            "NMSLFPLCCPGGALQVGGAMQVFGTAEGLLSFTS dhb\n",
            "NQWLHNAGIVCHLMAWA-DIQMFGMGEG--MCMF dhb\n",
            "GGLFHIGGAVMAGTLAGGAANAWGLTEFPVAASP dhb\n",
            "SASLFPMSSPGGSLQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SASLFPMSSPGGGLLVGGAQQVFGMAEGLVNYTR dhb\n",
            "SGSLFTMSSPGGSLQVGGSQQVFGMAEGLVNYTR dhb\n",
            "SRSLYAMSSPGGSLQVGGAQQVFGMAEGLVNYTA dhb\n",
            "SGSLFPLSSPGGALQVGGAQQVYGMAEGLVNYTR dhb\n",
            "QATLFTWGCPGGSLQLGGAQQVFGMAEGLLTLTR dhb\n",
            "SESLFPMSSPGGSLQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SGSLFPLSSPGGAVQVGGAQQVFGMAEGLVNYTR dhb\n",
            "NACVFLLSSPGGALQVGGAQQVFGMAEGLINYTR dhb\n",
            "NAVTHNLNMGCGGVFIA--HHIFGMTEGVIMFTR dhb\n",
            "NQSLYTLASFGGASQNGGAQEVYGTAEGLLNYTR dhb\n",
            "SASLFPLSSPGGAMQVGGAQQVFGMAEGLVNYTR dhb\n",
            "NAVQHNLNMGCGMLIAANSFHIFGITEGVIMFTH dhb\n",
            "NACLFTLCCPGGALQVGGAQQVFGMAEGLICCTR dhb\n",
            "HAWA---HLYAPVSFC----NMYGTTEGLLIGSG dhb\n",
            "SCALFTLSSPGGALWVGGAQQVFGMAEGLVNFTP dhb\n",
            "SKSLFCMSSPGGSLQVGGAQQVYGMAEGLVNFTH dhb\n",
            "SESLFSMSSAGGCLQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SKSLFTMSSPGGSLQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SASLYPMSSPASALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SASLFPMSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "NQCLFTLGCPGGALQVGGSQQVFGMAEGLIACTR dhb\n",
            "TESLFPMSSPGSALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "NASLFPLACPGGAVQVGGAQQVFGMAEGLLNFTR dhb\n",
            "NEYIHNAGVVCALLVLSGAWQLFGMGEGLFLTTR dhb\n",
            "SRSLYTMSSPGGPLQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SASIYPMSSPGGPLQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SMSLFPLSSPGGAVQVGGAQQVYGMAEGLVNYTR dhb\n",
            "STSLYPMSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SESLFPMSSPGGGLLVGGAQQVFGMAEGLVNYTR dhb\n",
            "YSLMHNAGVIGGLLLFSGK-QIFGMSEGLCLTTP dhb\n",
            "SGSLFPLSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SESLFPMSSPGGGLQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SRSLYPMSSPGGSLQVGGAQQVLGMAEGLVNYTR dhb\n",
            "SGSLYPLSSPGGALQVGGAQQVFGMAEGLVNYTR dhb\n",
            "SRSIFAASSPGGAAQVGGAQQVFGMAEGLVCYTR dhb\n",
            "LDSAFDPSLYAVHLGTGGDRNTYGPTETTLCATW dpg\n",
            "LDAAFDPSLYEVHLGTGGDRNTYGPTETTLCATW dpg\n",
            "LDPAFDASLYDVNFLAGGDWHTYGPTETTLCATW dpg\n",
            "LDEAFDPSLYAVHLGTGGDRNTYGPTETTLCATW dpg\n",
            "LDAAFDASLYEVHLGTGGDRNTYGPTETTLCATW dpg\n",
            "LDAAFDPSLYAVHLGTGGDRNTYGPTETTLCATW dpg\n",
            "LAHAFDVSIADQMIATGGEFNAYGPTEATVTATL crp\n",
            "VHTAFDAATFEGWLLAGGDINGYGPTETTTFAAA ile\n",
            "VDPAFDAGTLESWIMSGGDINGYGPTEGTVFTSL val\n",
            "LAVTFDASLIEMLILVGAEINGYGPTEATIATTF mha\n",
            "LDTSFDAATYEAFLWTGGEVHVYGPTETTTFAIC ile\n",
            "GSWAFDVFVSDHDTAGGADVNGYGVTEATVESCV lys\n",
            "RWWAFDIAVWEAHFVCGGEVHAYGPTETTITVVH hpg\n",
            "HWACFDVLVEEPNLVIGGQVNAYGPTEMTIGATA arg\n",
            "QWSAFDISLWEHHLVCGGENHTYGPTEASIIVTH hpg\n",
            "RWMTFDVSVWELHFISSGEHNLYGPTEATIDVTH ser\n",
            "RWSAFDIALWEFHFLSGGEHQAYGPAEASISVTH hpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Data:\")\n",
        "for batch_idx, batch in enumerate(train_loader):\n",
        "    sequences, labels = batch\n",
        "    print(\"Batch Sequences:\", sequences.shape)\n",
        "    print(\"Batch Labels:\", labels.shape)\n",
        "\n",
        "    \n",
        "    first_sequence = sequences[0]\n",
        "    first_label = labels[0]\n",
        "\n",
        "    print(\"First Sequence:\", first_sequence)\n",
        "    print(\"First Label:\", first_label)\n",
        "    break  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGi51IJ-XjWv",
        "outputId": "30917cfe-5d7b-4db9-841a-bc4c5bd2c85e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data:\n",
            "Batch Sequences: torch.Size([32, 34, 22])\n",
            "Batch Labels: torch.Size([32])\n",
            "First Sequence: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "First Label: tensor(29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ADomainModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size,num_layers, dropout):\n",
        "        super(ADomainModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size,num_layers=num_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = input.float()\n",
        "        output, _ = self.lstm(input)\n",
        "        output = output[:, -1, :]  \n",
        "        output = self.fc(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "eXktS2AgZ_zU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 22  # Number of amino acid types including the missing token and padding token\n",
        "hidden_size = 256\n",
        "batch_size = 32\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "output_size = len(dataset.label_map)\n",
        "model = ADomainModel(input_size, hidden_size, output_size,num_layers, dropout).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK3eKVkjaHlg",
        "outputId": "8efc577f-9b0c-4cdc-9ae9-b28b0d85ed67"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADomainModel(\n",
            "  (lstm): LSTM(22, 256, num_layers=2, dropout=0.2)\n",
            "  (fc): Linear(in_features=256, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the criterion (loss function)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "batch_size = 32\n",
        "\n",
        "# Define the optimizer\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Function for training the model\n",
        "def train(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        #print(inputs.shape)\n",
        "        inputs = inputs.to(device)\n",
        "        #inputs = inputs.view(batch_size, -1)\n",
        "        \n",
        "        labels = labels.to(device)\n",
        "        #print(labels.shape)\n",
        "        outputs = model(inputs)\n",
        "        #print(outputs.shape)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_predictions += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(dataloader)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "# Function for validating the model\n",
        "def validate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = running_loss / len(dataloader)\n",
        "    val_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    return val_loss, val_accuracy\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer)\n",
        "    val_loss, val_accuracy = validate(model, val_loader, criterion)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U13N9STkc27I",
        "outputId": "83ddccb0-68c4-4bdc-de3f-6b044e019e26"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500:\n",
            "Train Loss: 3.3608, Train Accuracy: 0.1152\n",
            "Validation Loss: 3.3288, Validation Accuracy: 0.0423\n",
            "Epoch 2/500:\n",
            "Train Loss: 3.1278, Train Accuracy: 0.1257\n",
            "Validation Loss: 3.5327, Validation Accuracy: 0.0423\n",
            "Epoch 3/500:\n",
            "Train Loss: 3.0641, Train Accuracy: 0.1361\n",
            "Validation Loss: 3.3664, Validation Accuracy: 0.0423\n",
            "Epoch 4/500:\n",
            "Train Loss: 3.0272, Train Accuracy: 0.1501\n",
            "Validation Loss: 3.3132, Validation Accuracy: 0.0563\n",
            "Epoch 5/500:\n",
            "Train Loss: 2.9335, Train Accuracy: 0.2042\n",
            "Validation Loss: 2.9800, Validation Accuracy: 0.2113\n",
            "Epoch 6/500:\n",
            "Train Loss: 2.8690, Train Accuracy: 0.2496\n",
            "Validation Loss: 2.8587, Validation Accuracy: 0.2535\n",
            "Epoch 7/500:\n",
            "Train Loss: 2.8161, Train Accuracy: 0.2496\n",
            "Validation Loss: 2.8922, Validation Accuracy: 0.2535\n",
            "Epoch 8/500:\n",
            "Train Loss: 2.7634, Train Accuracy: 0.2548\n",
            "Validation Loss: 2.8365, Validation Accuracy: 0.2535\n",
            "Epoch 9/500:\n",
            "Train Loss: 2.7054, Train Accuracy: 0.2688\n",
            "Validation Loss: 2.9687, Validation Accuracy: 0.2394\n",
            "Epoch 10/500:\n",
            "Train Loss: 2.6568, Train Accuracy: 0.2723\n",
            "Validation Loss: 2.9375, Validation Accuracy: 0.2958\n",
            "Epoch 11/500:\n",
            "Train Loss: 2.6288, Train Accuracy: 0.2862\n",
            "Validation Loss: 2.9323, Validation Accuracy: 0.3099\n",
            "Epoch 12/500:\n",
            "Train Loss: 2.5955, Train Accuracy: 0.2827\n",
            "Validation Loss: 2.8703, Validation Accuracy: 0.3380\n",
            "Epoch 13/500:\n",
            "Train Loss: 2.5585, Train Accuracy: 0.2862\n",
            "Validation Loss: 2.9525, Validation Accuracy: 0.3380\n",
            "Epoch 14/500:\n",
            "Train Loss: 2.5285, Train Accuracy: 0.2845\n",
            "Validation Loss: 3.0444, Validation Accuracy: 0.2817\n",
            "Epoch 15/500:\n",
            "Train Loss: 2.5259, Train Accuracy: 0.2792\n",
            "Validation Loss: 2.9698, Validation Accuracy: 0.3099\n",
            "Epoch 16/500:\n",
            "Train Loss: 2.4795, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.0418, Validation Accuracy: 0.2676\n",
            "Epoch 17/500:\n",
            "Train Loss: 2.4971, Train Accuracy: 0.2775\n",
            "Validation Loss: 2.9124, Validation Accuracy: 0.2817\n",
            "Epoch 18/500:\n",
            "Train Loss: 2.4561, Train Accuracy: 0.2880\n",
            "Validation Loss: 3.0409, Validation Accuracy: 0.2958\n",
            "Epoch 19/500:\n",
            "Train Loss: 2.4681, Train Accuracy: 0.2897\n",
            "Validation Loss: 2.9861, Validation Accuracy: 0.3239\n",
            "Epoch 20/500:\n",
            "Train Loss: 2.4275, Train Accuracy: 0.2757\n",
            "Validation Loss: 2.9929, Validation Accuracy: 0.2535\n",
            "Epoch 21/500:\n",
            "Train Loss: 2.4298, Train Accuracy: 0.2897\n",
            "Validation Loss: 2.9813, Validation Accuracy: 0.2958\n",
            "Epoch 22/500:\n",
            "Train Loss: 2.4013, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.9846, Validation Accuracy: 0.2817\n",
            "Epoch 23/500:\n",
            "Train Loss: 2.3783, Train Accuracy: 0.2949\n",
            "Validation Loss: 2.9630, Validation Accuracy: 0.2817\n",
            "Epoch 24/500:\n",
            "Train Loss: 2.3677, Train Accuracy: 0.2967\n",
            "Validation Loss: 2.9540, Validation Accuracy: 0.2958\n",
            "Epoch 25/500:\n",
            "Train Loss: 2.3769, Train Accuracy: 0.2862\n",
            "Validation Loss: 2.9013, Validation Accuracy: 0.2817\n",
            "Epoch 26/500:\n",
            "Train Loss: 2.3496, Train Accuracy: 0.2949\n",
            "Validation Loss: 2.9062, Validation Accuracy: 0.2958\n",
            "Epoch 27/500:\n",
            "Train Loss: 2.3607, Train Accuracy: 0.3106\n",
            "Validation Loss: 2.8724, Validation Accuracy: 0.2817\n",
            "Epoch 28/500:\n",
            "Train Loss: 2.3426, Train Accuracy: 0.3089\n",
            "Validation Loss: 2.9125, Validation Accuracy: 0.2958\n",
            "Epoch 29/500:\n",
            "Train Loss: 2.3361, Train Accuracy: 0.2897\n",
            "Validation Loss: 2.9567, Validation Accuracy: 0.2676\n",
            "Epoch 30/500:\n",
            "Train Loss: 2.3048, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.9622, Validation Accuracy: 0.3099\n",
            "Epoch 31/500:\n",
            "Train Loss: 2.3217, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.8892, Validation Accuracy: 0.2817\n",
            "Epoch 32/500:\n",
            "Train Loss: 2.3091, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.8100, Validation Accuracy: 0.2958\n",
            "Epoch 33/500:\n",
            "Train Loss: 2.3130, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.8260, Validation Accuracy: 0.3099\n",
            "Epoch 34/500:\n",
            "Train Loss: 2.2864, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.8114, Validation Accuracy: 0.3099\n",
            "Epoch 35/500:\n",
            "Train Loss: 2.2997, Train Accuracy: 0.2932\n",
            "Validation Loss: 2.8429, Validation Accuracy: 0.2817\n",
            "Epoch 36/500:\n",
            "Train Loss: 2.3188, Train Accuracy: 0.2880\n",
            "Validation Loss: 2.8802, Validation Accuracy: 0.2958\n",
            "Epoch 37/500:\n",
            "Train Loss: 2.3115, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.9134, Validation Accuracy: 0.2676\n",
            "Epoch 38/500:\n",
            "Train Loss: 2.2907, Train Accuracy: 0.2723\n",
            "Validation Loss: 2.9196, Validation Accuracy: 0.2958\n",
            "Epoch 39/500:\n",
            "Train Loss: 2.2974, Train Accuracy: 0.2949\n",
            "Validation Loss: 2.7946, Validation Accuracy: 0.3239\n",
            "Epoch 40/500:\n",
            "Train Loss: 2.2745, Train Accuracy: 0.2810\n",
            "Validation Loss: 2.7953, Validation Accuracy: 0.3380\n",
            "Epoch 41/500:\n",
            "Train Loss: 2.2672, Train Accuracy: 0.2984\n",
            "Validation Loss: 2.7801, Validation Accuracy: 0.3239\n",
            "Epoch 42/500:\n",
            "Train Loss: 2.2620, Train Accuracy: 0.2949\n",
            "Validation Loss: 2.7466, Validation Accuracy: 0.2958\n",
            "Epoch 43/500:\n",
            "Train Loss: 2.2664, Train Accuracy: 0.2984\n",
            "Validation Loss: 2.8183, Validation Accuracy: 0.3239\n",
            "Epoch 44/500:\n",
            "Train Loss: 2.2785, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.8149, Validation Accuracy: 0.2958\n",
            "Epoch 45/500:\n",
            "Train Loss: 2.2728, Train Accuracy: 0.2897\n",
            "Validation Loss: 2.8587, Validation Accuracy: 0.3099\n",
            "Epoch 46/500:\n",
            "Train Loss: 2.2490, Train Accuracy: 0.3141\n",
            "Validation Loss: 2.9178, Validation Accuracy: 0.3099\n",
            "Epoch 47/500:\n",
            "Train Loss: 2.2553, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.8629, Validation Accuracy: 0.2958\n",
            "Epoch 48/500:\n",
            "Train Loss: 2.2704, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.9062, Validation Accuracy: 0.2676\n",
            "Epoch 49/500:\n",
            "Train Loss: 2.2700, Train Accuracy: 0.2880\n",
            "Validation Loss: 2.9086, Validation Accuracy: 0.2958\n",
            "Epoch 50/500:\n",
            "Train Loss: 2.2602, Train Accuracy: 0.3124\n",
            "Validation Loss: 2.8583, Validation Accuracy: 0.2958\n",
            "Epoch 51/500:\n",
            "Train Loss: 2.2514, Train Accuracy: 0.2897\n",
            "Validation Loss: 2.9110, Validation Accuracy: 0.2958\n",
            "Epoch 52/500:\n",
            "Train Loss: 2.2520, Train Accuracy: 0.2897\n",
            "Validation Loss: 2.8698, Validation Accuracy: 0.3099\n",
            "Epoch 53/500:\n",
            "Train Loss: 2.2338, Train Accuracy: 0.3089\n",
            "Validation Loss: 2.9024, Validation Accuracy: 0.2817\n",
            "Epoch 54/500:\n",
            "Train Loss: 2.2739, Train Accuracy: 0.2897\n",
            "Validation Loss: 2.8880, Validation Accuracy: 0.3099\n",
            "Epoch 55/500:\n",
            "Train Loss: 2.2460, Train Accuracy: 0.2949\n",
            "Validation Loss: 2.8912, Validation Accuracy: 0.2817\n",
            "Epoch 56/500:\n",
            "Train Loss: 2.2511, Train Accuracy: 0.3072\n",
            "Validation Loss: 2.9023, Validation Accuracy: 0.2817\n",
            "Epoch 57/500:\n",
            "Train Loss: 2.2472, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.9035, Validation Accuracy: 0.2958\n",
            "Epoch 58/500:\n",
            "Train Loss: 2.2427, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.8732, Validation Accuracy: 0.2676\n",
            "Epoch 59/500:\n",
            "Train Loss: 2.2481, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.8961, Validation Accuracy: 0.2817\n",
            "Epoch 60/500:\n",
            "Train Loss: 2.2414, Train Accuracy: 0.2880\n",
            "Validation Loss: 2.8676, Validation Accuracy: 0.2394\n",
            "Epoch 61/500:\n",
            "Train Loss: 2.2228, Train Accuracy: 0.3089\n",
            "Validation Loss: 2.9382, Validation Accuracy: 0.2535\n",
            "Epoch 62/500:\n",
            "Train Loss: 2.2366, Train Accuracy: 0.2967\n",
            "Validation Loss: 2.9526, Validation Accuracy: 0.2676\n",
            "Epoch 63/500:\n",
            "Train Loss: 2.2379, Train Accuracy: 0.2932\n",
            "Validation Loss: 2.9080, Validation Accuracy: 0.2676\n",
            "Epoch 64/500:\n",
            "Train Loss: 2.2455, Train Accuracy: 0.2949\n",
            "Validation Loss: 2.8432, Validation Accuracy: 0.2676\n",
            "Epoch 65/500:\n",
            "Train Loss: 2.2217, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.8611, Validation Accuracy: 0.2958\n",
            "Epoch 66/500:\n",
            "Train Loss: 2.2522, Train Accuracy: 0.3072\n",
            "Validation Loss: 2.9169, Validation Accuracy: 0.2817\n",
            "Epoch 67/500:\n",
            "Train Loss: 2.2286, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.8841, Validation Accuracy: 0.2676\n",
            "Epoch 68/500:\n",
            "Train Loss: 2.2437, Train Accuracy: 0.2862\n",
            "Validation Loss: 2.9425, Validation Accuracy: 0.2676\n",
            "Epoch 69/500:\n",
            "Train Loss: 2.2258, Train Accuracy: 0.2914\n",
            "Validation Loss: 2.8827, Validation Accuracy: 0.2676\n",
            "Epoch 70/500:\n",
            "Train Loss: 2.2223, Train Accuracy: 0.2967\n",
            "Validation Loss: 2.8895, Validation Accuracy: 0.2817\n",
            "Epoch 71/500:\n",
            "Train Loss: 2.2246, Train Accuracy: 0.2914\n",
            "Validation Loss: 2.8512, Validation Accuracy: 0.2676\n",
            "Epoch 72/500:\n",
            "Train Loss: 2.2292, Train Accuracy: 0.3194\n",
            "Validation Loss: 2.8268, Validation Accuracy: 0.2817\n",
            "Epoch 73/500:\n",
            "Train Loss: 2.2305, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.8851, Validation Accuracy: 0.2817\n",
            "Epoch 74/500:\n",
            "Train Loss: 2.2357, Train Accuracy: 0.3089\n",
            "Validation Loss: 2.8842, Validation Accuracy: 0.2817\n",
            "Epoch 75/500:\n",
            "Train Loss: 2.2098, Train Accuracy: 0.3159\n",
            "Validation Loss: 2.8967, Validation Accuracy: 0.2817\n",
            "Epoch 76/500:\n",
            "Train Loss: 2.2095, Train Accuracy: 0.3106\n",
            "Validation Loss: 2.8967, Validation Accuracy: 0.2958\n",
            "Epoch 77/500:\n",
            "Train Loss: 2.2447, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9345, Validation Accuracy: 0.2817\n",
            "Epoch 78/500:\n",
            "Train Loss: 2.2208, Train Accuracy: 0.2897\n",
            "Validation Loss: 2.9300, Validation Accuracy: 0.2817\n",
            "Epoch 79/500:\n",
            "Train Loss: 2.2290, Train Accuracy: 0.3072\n",
            "Validation Loss: 2.9111, Validation Accuracy: 0.2958\n",
            "Epoch 80/500:\n",
            "Train Loss: 2.2186, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9155, Validation Accuracy: 0.2817\n",
            "Epoch 81/500:\n",
            "Train Loss: 2.2136, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.9492, Validation Accuracy: 0.2535\n",
            "Epoch 82/500:\n",
            "Train Loss: 2.2227, Train Accuracy: 0.2967\n",
            "Validation Loss: 2.9216, Validation Accuracy: 0.2958\n",
            "Epoch 83/500:\n",
            "Train Loss: 2.2147, Train Accuracy: 0.2932\n",
            "Validation Loss: 2.9398, Validation Accuracy: 0.2817\n",
            "Epoch 84/500:\n",
            "Train Loss: 2.2303, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.9544, Validation Accuracy: 0.2817\n",
            "Epoch 85/500:\n",
            "Train Loss: 2.2194, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.9542, Validation Accuracy: 0.3099\n",
            "Epoch 86/500:\n",
            "Train Loss: 2.2162, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.9471, Validation Accuracy: 0.2676\n",
            "Epoch 87/500:\n",
            "Train Loss: 2.2094, Train Accuracy: 0.3072\n",
            "Validation Loss: 2.9586, Validation Accuracy: 0.2676\n",
            "Epoch 88/500:\n",
            "Train Loss: 2.2292, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9362, Validation Accuracy: 0.2817\n",
            "Epoch 89/500:\n",
            "Train Loss: 2.2129, Train Accuracy: 0.3089\n",
            "Validation Loss: 2.9006, Validation Accuracy: 0.2958\n",
            "Epoch 90/500:\n",
            "Train Loss: 2.2040, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.9358, Validation Accuracy: 0.2817\n",
            "Epoch 91/500:\n",
            "Train Loss: 2.2063, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.9655, Validation Accuracy: 0.2958\n",
            "Epoch 92/500:\n",
            "Train Loss: 2.2285, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.9713, Validation Accuracy: 0.3239\n",
            "Epoch 93/500:\n",
            "Train Loss: 2.2239, Train Accuracy: 0.2967\n",
            "Validation Loss: 2.9866, Validation Accuracy: 0.2958\n",
            "Epoch 94/500:\n",
            "Train Loss: 2.2144, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.9920, Validation Accuracy: 0.3239\n",
            "Epoch 95/500:\n",
            "Train Loss: 2.2143, Train Accuracy: 0.3211\n",
            "Validation Loss: 3.0482, Validation Accuracy: 0.3099\n",
            "Epoch 96/500:\n",
            "Train Loss: 2.2082, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.0426, Validation Accuracy: 0.2817\n",
            "Epoch 97/500:\n",
            "Train Loss: 2.1978, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0379, Validation Accuracy: 0.3099\n",
            "Epoch 98/500:\n",
            "Train Loss: 2.2163, Train Accuracy: 0.2932\n",
            "Validation Loss: 2.9933, Validation Accuracy: 0.3099\n",
            "Epoch 99/500:\n",
            "Train Loss: 2.2241, Train Accuracy: 0.2967\n",
            "Validation Loss: 2.9728, Validation Accuracy: 0.2958\n",
            "Epoch 100/500:\n",
            "Train Loss: 2.2017, Train Accuracy: 0.3124\n",
            "Validation Loss: 2.9572, Validation Accuracy: 0.2817\n",
            "Epoch 101/500:\n",
            "Train Loss: 2.2039, Train Accuracy: 0.2984\n",
            "Validation Loss: 2.9315, Validation Accuracy: 0.3099\n",
            "Epoch 102/500:\n",
            "Train Loss: 2.2051, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9270, Validation Accuracy: 0.2817\n",
            "Epoch 103/500:\n",
            "Train Loss: 2.2176, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.9694, Validation Accuracy: 0.2394\n",
            "Epoch 104/500:\n",
            "Train Loss: 2.2031, Train Accuracy: 0.3141\n",
            "Validation Loss: 2.9554, Validation Accuracy: 0.2535\n",
            "Epoch 105/500:\n",
            "Train Loss: 2.2074, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.9397, Validation Accuracy: 0.2676\n",
            "Epoch 106/500:\n",
            "Train Loss: 2.2167, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.9420, Validation Accuracy: 0.2958\n",
            "Epoch 107/500:\n",
            "Train Loss: 2.2042, Train Accuracy: 0.2949\n",
            "Validation Loss: 2.9339, Validation Accuracy: 0.2676\n",
            "Epoch 108/500:\n",
            "Train Loss: 2.2163, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0022, Validation Accuracy: 0.2817\n",
            "Epoch 109/500:\n",
            "Train Loss: 2.2012, Train Accuracy: 0.2967\n",
            "Validation Loss: 2.9801, Validation Accuracy: 0.2958\n",
            "Epoch 110/500:\n",
            "Train Loss: 2.2109, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9520, Validation Accuracy: 0.2958\n",
            "Epoch 111/500:\n",
            "Train Loss: 2.2106, Train Accuracy: 0.3072\n",
            "Validation Loss: 2.8998, Validation Accuracy: 0.2817\n",
            "Epoch 112/500:\n",
            "Train Loss: 2.2066, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.9117, Validation Accuracy: 0.2958\n",
            "Epoch 113/500:\n",
            "Train Loss: 2.2047, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.9315, Validation Accuracy: 0.2676\n",
            "Epoch 114/500:\n",
            "Train Loss: 2.2033, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.9749, Validation Accuracy: 0.2958\n",
            "Epoch 115/500:\n",
            "Train Loss: 2.2015, Train Accuracy: 0.3089\n",
            "Validation Loss: 2.9782, Validation Accuracy: 0.2535\n",
            "Epoch 116/500:\n",
            "Train Loss: 2.1991, Train Accuracy: 0.3159\n",
            "Validation Loss: 2.9741, Validation Accuracy: 0.2676\n",
            "Epoch 117/500:\n",
            "Train Loss: 2.2050, Train Accuracy: 0.2967\n",
            "Validation Loss: 2.9881, Validation Accuracy: 0.2958\n",
            "Epoch 118/500:\n",
            "Train Loss: 2.2102, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0038, Validation Accuracy: 0.2958\n",
            "Epoch 119/500:\n",
            "Train Loss: 2.2083, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.0137, Validation Accuracy: 0.2676\n",
            "Epoch 120/500:\n",
            "Train Loss: 2.2087, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.0041, Validation Accuracy: 0.2817\n",
            "Epoch 121/500:\n",
            "Train Loss: 2.2111, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0027, Validation Accuracy: 0.2817\n",
            "Epoch 122/500:\n",
            "Train Loss: 2.1970, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.0175, Validation Accuracy: 0.2817\n",
            "Epoch 123/500:\n",
            "Train Loss: 2.1968, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0250, Validation Accuracy: 0.2817\n",
            "Epoch 124/500:\n",
            "Train Loss: 2.2055, Train Accuracy: 0.2949\n",
            "Validation Loss: 3.0464, Validation Accuracy: 0.2535\n",
            "Epoch 125/500:\n",
            "Train Loss: 2.2185, Train Accuracy: 0.3089\n",
            "Validation Loss: 2.9711, Validation Accuracy: 0.2817\n",
            "Epoch 126/500:\n",
            "Train Loss: 2.2214, Train Accuracy: 0.3072\n",
            "Validation Loss: 2.9812, Validation Accuracy: 0.2817\n",
            "Epoch 127/500:\n",
            "Train Loss: 2.2049, Train Accuracy: 0.2932\n",
            "Validation Loss: 2.9295, Validation Accuracy: 0.2676\n",
            "Epoch 128/500:\n",
            "Train Loss: 2.1976, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9586, Validation Accuracy: 0.2958\n",
            "Epoch 129/500:\n",
            "Train Loss: 2.2017, Train Accuracy: 0.3106\n",
            "Validation Loss: 2.9202, Validation Accuracy: 0.2958\n",
            "Epoch 130/500:\n",
            "Train Loss: 2.1877, Train Accuracy: 0.3159\n",
            "Validation Loss: 2.9395, Validation Accuracy: 0.2817\n",
            "Epoch 131/500:\n",
            "Train Loss: 2.2089, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0028, Validation Accuracy: 0.3099\n",
            "Epoch 132/500:\n",
            "Train Loss: 2.2188, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0023, Validation Accuracy: 0.2958\n",
            "Epoch 133/500:\n",
            "Train Loss: 2.2303, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.9751, Validation Accuracy: 0.2958\n",
            "Epoch 134/500:\n",
            "Train Loss: 2.2146, Train Accuracy: 0.3124\n",
            "Validation Loss: 2.9821, Validation Accuracy: 0.2958\n",
            "Epoch 135/500:\n",
            "Train Loss: 2.2088, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9913, Validation Accuracy: 0.2676\n",
            "Epoch 136/500:\n",
            "Train Loss: 2.1947, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0150, Validation Accuracy: 0.2817\n",
            "Epoch 137/500:\n",
            "Train Loss: 2.2131, Train Accuracy: 0.3002\n",
            "Validation Loss: 2.9927, Validation Accuracy: 0.2817\n",
            "Epoch 138/500:\n",
            "Train Loss: 2.2064, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.9981, Validation Accuracy: 0.2817\n",
            "Epoch 139/500:\n",
            "Train Loss: 2.1870, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0008, Validation Accuracy: 0.2958\n",
            "Epoch 140/500:\n",
            "Train Loss: 2.1964, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.0200, Validation Accuracy: 0.3099\n",
            "Epoch 141/500:\n",
            "Train Loss: 2.1961, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9935, Validation Accuracy: 0.2958\n",
            "Epoch 142/500:\n",
            "Train Loss: 2.1955, Train Accuracy: 0.3089\n",
            "Validation Loss: 2.9937, Validation Accuracy: 0.2958\n",
            "Epoch 143/500:\n",
            "Train Loss: 2.1965, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.0098, Validation Accuracy: 0.2958\n",
            "Epoch 144/500:\n",
            "Train Loss: 2.2004, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.9797, Validation Accuracy: 0.2958\n",
            "Epoch 145/500:\n",
            "Train Loss: 2.2088, Train Accuracy: 0.3054\n",
            "Validation Loss: 2.9841, Validation Accuracy: 0.2817\n",
            "Epoch 146/500:\n",
            "Train Loss: 2.1940, Train Accuracy: 0.3106\n",
            "Validation Loss: 2.9925, Validation Accuracy: 0.2958\n",
            "Epoch 147/500:\n",
            "Train Loss: 2.1988, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0027, Validation Accuracy: 0.3099\n",
            "Epoch 148/500:\n",
            "Train Loss: 2.1881, Train Accuracy: 0.3089\n",
            "Validation Loss: 2.9992, Validation Accuracy: 0.2958\n",
            "Epoch 149/500:\n",
            "Train Loss: 2.1944, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.0273, Validation Accuracy: 0.2958\n",
            "Epoch 150/500:\n",
            "Train Loss: 2.1978, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0227, Validation Accuracy: 0.3099\n",
            "Epoch 151/500:\n",
            "Train Loss: 2.1983, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0120, Validation Accuracy: 0.2958\n",
            "Epoch 152/500:\n",
            "Train Loss: 2.1879, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0337, Validation Accuracy: 0.2958\n",
            "Epoch 153/500:\n",
            "Train Loss: 2.1939, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.9817, Validation Accuracy: 0.2958\n",
            "Epoch 154/500:\n",
            "Train Loss: 2.1970, Train Accuracy: 0.3124\n",
            "Validation Loss: 2.9836, Validation Accuracy: 0.3099\n",
            "Epoch 155/500:\n",
            "Train Loss: 2.1980, Train Accuracy: 0.2914\n",
            "Validation Loss: 2.9956, Validation Accuracy: 0.2958\n",
            "Epoch 156/500:\n",
            "Train Loss: 2.1945, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.0242, Validation Accuracy: 0.2958\n",
            "Epoch 157/500:\n",
            "Train Loss: 2.1990, Train Accuracy: 0.3106\n",
            "Validation Loss: 2.9895, Validation Accuracy: 0.3099\n",
            "Epoch 158/500:\n",
            "Train Loss: 2.1915, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.0355, Validation Accuracy: 0.2817\n",
            "Epoch 159/500:\n",
            "Train Loss: 2.1846, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0060, Validation Accuracy: 0.2676\n",
            "Epoch 160/500:\n",
            "Train Loss: 2.1948, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0115, Validation Accuracy: 0.3099\n",
            "Epoch 161/500:\n",
            "Train Loss: 2.2054, Train Accuracy: 0.2897\n",
            "Validation Loss: 3.0215, Validation Accuracy: 0.3099\n",
            "Epoch 162/500:\n",
            "Train Loss: 2.1862, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0509, Validation Accuracy: 0.2958\n",
            "Epoch 163/500:\n",
            "Train Loss: 2.1868, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0447, Validation Accuracy: 0.2958\n",
            "Epoch 164/500:\n",
            "Train Loss: 2.2041, Train Accuracy: 0.3072\n",
            "Validation Loss: 2.9971, Validation Accuracy: 0.3099\n",
            "Epoch 165/500:\n",
            "Train Loss: 2.1975, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.0048, Validation Accuracy: 0.2958\n",
            "Epoch 166/500:\n",
            "Train Loss: 2.1844, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.0102, Validation Accuracy: 0.3099\n",
            "Epoch 167/500:\n",
            "Train Loss: 2.1943, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0120, Validation Accuracy: 0.3099\n",
            "Epoch 168/500:\n",
            "Train Loss: 2.1906, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.0330, Validation Accuracy: 0.2958\n",
            "Epoch 169/500:\n",
            "Train Loss: 2.1954, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0364, Validation Accuracy: 0.2958\n",
            "Epoch 170/500:\n",
            "Train Loss: 2.2065, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9664, Validation Accuracy: 0.2958\n",
            "Epoch 171/500:\n",
            "Train Loss: 2.1951, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.0080, Validation Accuracy: 0.2817\n",
            "Epoch 172/500:\n",
            "Train Loss: 2.1920, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.0058, Validation Accuracy: 0.3099\n",
            "Epoch 173/500:\n",
            "Train Loss: 2.1944, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.0182, Validation Accuracy: 0.3099\n",
            "Epoch 174/500:\n",
            "Train Loss: 2.1900, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0225, Validation Accuracy: 0.3099\n",
            "Epoch 175/500:\n",
            "Train Loss: 2.1933, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0343, Validation Accuracy: 0.2958\n",
            "Epoch 176/500:\n",
            "Train Loss: 2.1976, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.0176, Validation Accuracy: 0.2958\n",
            "Epoch 177/500:\n",
            "Train Loss: 2.1889, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.0243, Validation Accuracy: 0.2676\n",
            "Epoch 178/500:\n",
            "Train Loss: 2.1960, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.0006, Validation Accuracy: 0.2958\n",
            "Epoch 179/500:\n",
            "Train Loss: 2.1865, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.0154, Validation Accuracy: 0.3099\n",
            "Epoch 180/500:\n",
            "Train Loss: 2.1914, Train Accuracy: 0.3019\n",
            "Validation Loss: 2.9996, Validation Accuracy: 0.2676\n",
            "Epoch 181/500:\n",
            "Train Loss: 2.1866, Train Accuracy: 0.3124\n",
            "Validation Loss: 2.9716, Validation Accuracy: 0.3239\n",
            "Epoch 182/500:\n",
            "Train Loss: 2.1956, Train Accuracy: 0.3124\n",
            "Validation Loss: 2.9720, Validation Accuracy: 0.2676\n",
            "Epoch 183/500:\n",
            "Train Loss: 2.2009, Train Accuracy: 0.3106\n",
            "Validation Loss: 2.9955, Validation Accuracy: 0.2958\n",
            "Epoch 184/500:\n",
            "Train Loss: 2.1942, Train Accuracy: 0.3072\n",
            "Validation Loss: 2.9988, Validation Accuracy: 0.3099\n",
            "Epoch 185/500:\n",
            "Train Loss: 2.1886, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.0336, Validation Accuracy: 0.2676\n",
            "Epoch 186/500:\n",
            "Train Loss: 2.1927, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.0506, Validation Accuracy: 0.2535\n",
            "Epoch 187/500:\n",
            "Train Loss: 2.1886, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0399, Validation Accuracy: 0.2958\n",
            "Epoch 188/500:\n",
            "Train Loss: 2.1848, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0526, Validation Accuracy: 0.2817\n",
            "Epoch 189/500:\n",
            "Train Loss: 2.1998, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0279, Validation Accuracy: 0.2535\n",
            "Epoch 190/500:\n",
            "Train Loss: 2.1976, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.0075, Validation Accuracy: 0.2676\n",
            "Epoch 191/500:\n",
            "Train Loss: 2.1872, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.0193, Validation Accuracy: 0.2676\n",
            "Epoch 192/500:\n",
            "Train Loss: 2.1966, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.0055, Validation Accuracy: 0.2676\n",
            "Epoch 193/500:\n",
            "Train Loss: 2.1945, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0212, Validation Accuracy: 0.3099\n",
            "Epoch 194/500:\n",
            "Train Loss: 2.1929, Train Accuracy: 0.3037\n",
            "Validation Loss: 2.9792, Validation Accuracy: 0.2958\n",
            "Epoch 195/500:\n",
            "Train Loss: 2.1913, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0255, Validation Accuracy: 0.2958\n",
            "Epoch 196/500:\n",
            "Train Loss: 2.2074, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0045, Validation Accuracy: 0.2676\n",
            "Epoch 197/500:\n",
            "Train Loss: 2.1878, Train Accuracy: 0.3124\n",
            "Validation Loss: 2.9748, Validation Accuracy: 0.2817\n",
            "Epoch 198/500:\n",
            "Train Loss: 2.1912, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.0031, Validation Accuracy: 0.2676\n",
            "Epoch 199/500:\n",
            "Train Loss: 2.1906, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.0253, Validation Accuracy: 0.2676\n",
            "Epoch 200/500:\n",
            "Train Loss: 2.1909, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0715, Validation Accuracy: 0.2817\n",
            "Epoch 201/500:\n",
            "Train Loss: 2.1902, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0427, Validation Accuracy: 0.2676\n",
            "Epoch 202/500:\n",
            "Train Loss: 2.1920, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0234, Validation Accuracy: 0.2958\n",
            "Epoch 203/500:\n",
            "Train Loss: 2.1953, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.0340, Validation Accuracy: 0.2817\n",
            "Epoch 204/500:\n",
            "Train Loss: 2.1957, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0312, Validation Accuracy: 0.2676\n",
            "Epoch 205/500:\n",
            "Train Loss: 2.1833, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0078, Validation Accuracy: 0.2676\n",
            "Epoch 206/500:\n",
            "Train Loss: 2.1962, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0027, Validation Accuracy: 0.2817\n",
            "Epoch 207/500:\n",
            "Train Loss: 2.1898, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0252, Validation Accuracy: 0.2958\n",
            "Epoch 208/500:\n",
            "Train Loss: 2.1877, Train Accuracy: 0.3176\n",
            "Validation Loss: 3.0128, Validation Accuracy: 0.2817\n",
            "Epoch 209/500:\n",
            "Train Loss: 2.1842, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.0408, Validation Accuracy: 0.2817\n",
            "Epoch 210/500:\n",
            "Train Loss: 2.2028, Train Accuracy: 0.2984\n",
            "Validation Loss: 2.9920, Validation Accuracy: 0.3099\n",
            "Epoch 211/500:\n",
            "Train Loss: 2.1906, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0236, Validation Accuracy: 0.2676\n",
            "Epoch 212/500:\n",
            "Train Loss: 2.1856, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0373, Validation Accuracy: 0.2817\n",
            "Epoch 213/500:\n",
            "Train Loss: 2.1943, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0644, Validation Accuracy: 0.2676\n",
            "Epoch 214/500:\n",
            "Train Loss: 2.2010, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.0656, Validation Accuracy: 0.2676\n",
            "Epoch 215/500:\n",
            "Train Loss: 2.1835, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.0600, Validation Accuracy: 0.2958\n",
            "Epoch 216/500:\n",
            "Train Loss: 2.2041, Train Accuracy: 0.2949\n",
            "Validation Loss: 3.0363, Validation Accuracy: 0.2958\n",
            "Epoch 217/500:\n",
            "Train Loss: 2.1911, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.0131, Validation Accuracy: 0.3099\n",
            "Epoch 218/500:\n",
            "Train Loss: 2.1838, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.0113, Validation Accuracy: 0.3099\n",
            "Epoch 219/500:\n",
            "Train Loss: 2.1958, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.0499, Validation Accuracy: 0.2958\n",
            "Epoch 220/500:\n",
            "Train Loss: 2.1864, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0542, Validation Accuracy: 0.2958\n",
            "Epoch 221/500:\n",
            "Train Loss: 2.1884, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.0800, Validation Accuracy: 0.3099\n",
            "Epoch 222/500:\n",
            "Train Loss: 2.1817, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.0830, Validation Accuracy: 0.3099\n",
            "Epoch 223/500:\n",
            "Train Loss: 2.1885, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0955, Validation Accuracy: 0.3099\n",
            "Epoch 224/500:\n",
            "Train Loss: 2.1864, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0666, Validation Accuracy: 0.2958\n",
            "Epoch 225/500:\n",
            "Train Loss: 2.1857, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0981, Validation Accuracy: 0.2817\n",
            "Epoch 226/500:\n",
            "Train Loss: 2.1828, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0783, Validation Accuracy: 0.3099\n",
            "Epoch 227/500:\n",
            "Train Loss: 2.1869, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0599, Validation Accuracy: 0.3239\n",
            "Epoch 228/500:\n",
            "Train Loss: 2.1882, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0495, Validation Accuracy: 0.3099\n",
            "Epoch 229/500:\n",
            "Train Loss: 2.1942, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0296, Validation Accuracy: 0.2958\n",
            "Epoch 230/500:\n",
            "Train Loss: 2.1889, Train Accuracy: 0.3176\n",
            "Validation Loss: 3.0800, Validation Accuracy: 0.2817\n",
            "Epoch 231/500:\n",
            "Train Loss: 2.2001, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.0668, Validation Accuracy: 0.2958\n",
            "Epoch 232/500:\n",
            "Train Loss: 2.1877, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0669, Validation Accuracy: 0.2958\n",
            "Epoch 233/500:\n",
            "Train Loss: 2.1932, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.0561, Validation Accuracy: 0.2958\n",
            "Epoch 234/500:\n",
            "Train Loss: 2.1918, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0369, Validation Accuracy: 0.2958\n",
            "Epoch 235/500:\n",
            "Train Loss: 2.1964, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0386, Validation Accuracy: 0.2958\n",
            "Epoch 236/500:\n",
            "Train Loss: 2.1841, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.0846, Validation Accuracy: 0.2817\n",
            "Epoch 237/500:\n",
            "Train Loss: 2.1834, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0847, Validation Accuracy: 0.3099\n",
            "Epoch 238/500:\n",
            "Train Loss: 2.2054, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0655, Validation Accuracy: 0.3099\n",
            "Epoch 239/500:\n",
            "Train Loss: 2.1801, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.0557, Validation Accuracy: 0.2958\n",
            "Epoch 240/500:\n",
            "Train Loss: 2.1889, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0665, Validation Accuracy: 0.3099\n",
            "Epoch 241/500:\n",
            "Train Loss: 2.1880, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.0613, Validation Accuracy: 0.2676\n",
            "Epoch 242/500:\n",
            "Train Loss: 2.1807, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0834, Validation Accuracy: 0.3099\n",
            "Epoch 243/500:\n",
            "Train Loss: 2.1770, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0671, Validation Accuracy: 0.2958\n",
            "Epoch 244/500:\n",
            "Train Loss: 2.1802, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.1070, Validation Accuracy: 0.3239\n",
            "Epoch 245/500:\n",
            "Train Loss: 2.1944, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0972, Validation Accuracy: 0.2958\n",
            "Epoch 246/500:\n",
            "Train Loss: 2.1830, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.1003, Validation Accuracy: 0.3380\n",
            "Epoch 247/500:\n",
            "Train Loss: 2.1846, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1609, Validation Accuracy: 0.3380\n",
            "Epoch 248/500:\n",
            "Train Loss: 2.1937, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.0853, Validation Accuracy: 0.3239\n",
            "Epoch 249/500:\n",
            "Train Loss: 2.2005, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.0954, Validation Accuracy: 0.3099\n",
            "Epoch 250/500:\n",
            "Train Loss: 2.1963, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.0792, Validation Accuracy: 0.2958\n",
            "Epoch 251/500:\n",
            "Train Loss: 2.1856, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1043, Validation Accuracy: 0.2958\n",
            "Epoch 252/500:\n",
            "Train Loss: 2.1837, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.1079, Validation Accuracy: 0.2817\n",
            "Epoch 253/500:\n",
            "Train Loss: 2.1924, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.0941, Validation Accuracy: 0.2817\n",
            "Epoch 254/500:\n",
            "Train Loss: 2.1853, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.1287, Validation Accuracy: 0.3380\n",
            "Epoch 255/500:\n",
            "Train Loss: 2.1806, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1168, Validation Accuracy: 0.3099\n",
            "Epoch 256/500:\n",
            "Train Loss: 2.1847, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1752, Validation Accuracy: 0.3380\n",
            "Epoch 257/500:\n",
            "Train Loss: 2.1917, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1047, Validation Accuracy: 0.2958\n",
            "Epoch 258/500:\n",
            "Train Loss: 2.1839, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0861, Validation Accuracy: 0.2958\n",
            "Epoch 259/500:\n",
            "Train Loss: 2.1828, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.1153, Validation Accuracy: 0.3099\n",
            "Epoch 260/500:\n",
            "Train Loss: 2.1866, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1204, Validation Accuracy: 0.2958\n",
            "Epoch 261/500:\n",
            "Train Loss: 2.1889, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.1137, Validation Accuracy: 0.2958\n",
            "Epoch 262/500:\n",
            "Train Loss: 2.1841, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.1149, Validation Accuracy: 0.2958\n",
            "Epoch 263/500:\n",
            "Train Loss: 2.1843, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1202, Validation Accuracy: 0.2958\n",
            "Epoch 264/500:\n",
            "Train Loss: 2.1893, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1099, Validation Accuracy: 0.2676\n",
            "Epoch 265/500:\n",
            "Train Loss: 2.1950, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.1060, Validation Accuracy: 0.2676\n",
            "Epoch 266/500:\n",
            "Train Loss: 2.1970, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.0861, Validation Accuracy: 0.2958\n",
            "Epoch 267/500:\n",
            "Train Loss: 2.1919, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.0931, Validation Accuracy: 0.2817\n",
            "Epoch 268/500:\n",
            "Train Loss: 2.1976, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.0845, Validation Accuracy: 0.2958\n",
            "Epoch 269/500:\n",
            "Train Loss: 2.1875, Train Accuracy: 0.2949\n",
            "Validation Loss: 3.0803, Validation Accuracy: 0.2958\n",
            "Epoch 270/500:\n",
            "Train Loss: 2.2009, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.0801, Validation Accuracy: 0.2817\n",
            "Epoch 271/500:\n",
            "Train Loss: 2.1880, Train Accuracy: 0.3194\n",
            "Validation Loss: 3.0934, Validation Accuracy: 0.2676\n",
            "Epoch 272/500:\n",
            "Train Loss: 2.1714, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.0920, Validation Accuracy: 0.2817\n",
            "Epoch 273/500:\n",
            "Train Loss: 2.1903, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.1106, Validation Accuracy: 0.2958\n",
            "Epoch 274/500:\n",
            "Train Loss: 2.1844, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1184, Validation Accuracy: 0.2817\n",
            "Epoch 275/500:\n",
            "Train Loss: 2.1773, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1317, Validation Accuracy: 0.2817\n",
            "Epoch 276/500:\n",
            "Train Loss: 2.1842, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1111, Validation Accuracy: 0.3099\n",
            "Epoch 277/500:\n",
            "Train Loss: 2.1776, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.1393, Validation Accuracy: 0.2817\n",
            "Epoch 278/500:\n",
            "Train Loss: 2.1820, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.1240, Validation Accuracy: 0.2958\n",
            "Epoch 279/500:\n",
            "Train Loss: 2.1923, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1302, Validation Accuracy: 0.2817\n",
            "Epoch 280/500:\n",
            "Train Loss: 2.1893, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1140, Validation Accuracy: 0.2958\n",
            "Epoch 281/500:\n",
            "Train Loss: 2.1831, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.1118, Validation Accuracy: 0.3099\n",
            "Epoch 282/500:\n",
            "Train Loss: 2.1892, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1165, Validation Accuracy: 0.2958\n",
            "Epoch 283/500:\n",
            "Train Loss: 2.1876, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1041, Validation Accuracy: 0.3099\n",
            "Epoch 284/500:\n",
            "Train Loss: 2.1810, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1076, Validation Accuracy: 0.2958\n",
            "Epoch 285/500:\n",
            "Train Loss: 2.1819, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.1108, Validation Accuracy: 0.2958\n",
            "Epoch 286/500:\n",
            "Train Loss: 2.1772, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.0995, Validation Accuracy: 0.2958\n",
            "Epoch 287/500:\n",
            "Train Loss: 2.1767, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1125, Validation Accuracy: 0.2676\n",
            "Epoch 288/500:\n",
            "Train Loss: 2.1719, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.1257, Validation Accuracy: 0.2958\n",
            "Epoch 289/500:\n",
            "Train Loss: 2.1825, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1081, Validation Accuracy: 0.2958\n",
            "Epoch 290/500:\n",
            "Train Loss: 2.1756, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.0814, Validation Accuracy: 0.2817\n",
            "Epoch 291/500:\n",
            "Train Loss: 2.1836, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.1118, Validation Accuracy: 0.3099\n",
            "Epoch 292/500:\n",
            "Train Loss: 2.1775, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1145, Validation Accuracy: 0.3099\n",
            "Epoch 293/500:\n",
            "Train Loss: 2.1805, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.1187, Validation Accuracy: 0.2817\n",
            "Epoch 294/500:\n",
            "Train Loss: 2.1749, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1041, Validation Accuracy: 0.2958\n",
            "Epoch 295/500:\n",
            "Train Loss: 2.1872, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.1154, Validation Accuracy: 0.2958\n",
            "Epoch 296/500:\n",
            "Train Loss: 2.1855, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.1161, Validation Accuracy: 0.2817\n",
            "Epoch 297/500:\n",
            "Train Loss: 2.1876, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.1287, Validation Accuracy: 0.2676\n",
            "Epoch 298/500:\n",
            "Train Loss: 2.1879, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.1255, Validation Accuracy: 0.3099\n",
            "Epoch 299/500:\n",
            "Train Loss: 2.1898, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1431, Validation Accuracy: 0.3099\n",
            "Epoch 300/500:\n",
            "Train Loss: 2.1731, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.1425, Validation Accuracy: 0.3099\n",
            "Epoch 301/500:\n",
            "Train Loss: 2.1753, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1524, Validation Accuracy: 0.3099\n",
            "Epoch 302/500:\n",
            "Train Loss: 2.1869, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1540, Validation Accuracy: 0.2958\n",
            "Epoch 303/500:\n",
            "Train Loss: 2.1823, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1389, Validation Accuracy: 0.2817\n",
            "Epoch 304/500:\n",
            "Train Loss: 2.1786, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1944, Validation Accuracy: 0.2958\n",
            "Epoch 305/500:\n",
            "Train Loss: 2.1838, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1884, Validation Accuracy: 0.2817\n",
            "Epoch 306/500:\n",
            "Train Loss: 2.1855, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.1707, Validation Accuracy: 0.2958\n",
            "Epoch 307/500:\n",
            "Train Loss: 2.1715, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.1759, Validation Accuracy: 0.2817\n",
            "Epoch 308/500:\n",
            "Train Loss: 2.1833, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.1827, Validation Accuracy: 0.2817\n",
            "Epoch 309/500:\n",
            "Train Loss: 2.1803, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1398, Validation Accuracy: 0.2958\n",
            "Epoch 310/500:\n",
            "Train Loss: 2.1826, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1209, Validation Accuracy: 0.2958\n",
            "Epoch 311/500:\n",
            "Train Loss: 2.1883, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1696, Validation Accuracy: 0.2817\n",
            "Epoch 312/500:\n",
            "Train Loss: 2.1845, Train Accuracy: 0.3211\n",
            "Validation Loss: 3.1709, Validation Accuracy: 0.2817\n",
            "Epoch 313/500:\n",
            "Train Loss: 2.1798, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.1861, Validation Accuracy: 0.2817\n",
            "Epoch 314/500:\n",
            "Train Loss: 2.1827, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.1759, Validation Accuracy: 0.2817\n",
            "Epoch 315/500:\n",
            "Train Loss: 2.1838, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2013, Validation Accuracy: 0.2817\n",
            "Epoch 316/500:\n",
            "Train Loss: 2.1813, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.2040, Validation Accuracy: 0.2958\n",
            "Epoch 317/500:\n",
            "Train Loss: 2.1740, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2041, Validation Accuracy: 0.3099\n",
            "Epoch 318/500:\n",
            "Train Loss: 2.1857, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.1867, Validation Accuracy: 0.2958\n",
            "Epoch 319/500:\n",
            "Train Loss: 2.1864, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.2150, Validation Accuracy: 0.2817\n",
            "Epoch 320/500:\n",
            "Train Loss: 2.1804, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1995, Validation Accuracy: 0.3099\n",
            "Epoch 321/500:\n",
            "Train Loss: 2.1864, Train Accuracy: 0.3194\n",
            "Validation Loss: 3.2081, Validation Accuracy: 0.3099\n",
            "Epoch 322/500:\n",
            "Train Loss: 2.1784, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2031, Validation Accuracy: 0.3099\n",
            "Epoch 323/500:\n",
            "Train Loss: 2.1797, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1830, Validation Accuracy: 0.2958\n",
            "Epoch 324/500:\n",
            "Train Loss: 2.1865, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.1519, Validation Accuracy: 0.2817\n",
            "Epoch 325/500:\n",
            "Train Loss: 2.1857, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1878, Validation Accuracy: 0.3099\n",
            "Epoch 326/500:\n",
            "Train Loss: 2.1832, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.1885, Validation Accuracy: 0.2958\n",
            "Epoch 327/500:\n",
            "Train Loss: 2.1789, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1603, Validation Accuracy: 0.2958\n",
            "Epoch 328/500:\n",
            "Train Loss: 2.1921, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.1921, Validation Accuracy: 0.2958\n",
            "Epoch 329/500:\n",
            "Train Loss: 2.1747, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2022, Validation Accuracy: 0.2676\n",
            "Epoch 330/500:\n",
            "Train Loss: 2.1928, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.1590, Validation Accuracy: 0.2817\n",
            "Epoch 331/500:\n",
            "Train Loss: 2.1778, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2047, Validation Accuracy: 0.2817\n",
            "Epoch 332/500:\n",
            "Train Loss: 2.1855, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2410, Validation Accuracy: 0.2676\n",
            "Epoch 333/500:\n",
            "Train Loss: 2.1746, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.3210, Validation Accuracy: 0.2958\n",
            "Epoch 334/500:\n",
            "Train Loss: 2.1749, Train Accuracy: 0.3176\n",
            "Validation Loss: 3.2815, Validation Accuracy: 0.2817\n",
            "Epoch 335/500:\n",
            "Train Loss: 2.2065, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2780, Validation Accuracy: 0.2676\n",
            "Epoch 336/500:\n",
            "Train Loss: 2.1876, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2341, Validation Accuracy: 0.2817\n",
            "Epoch 337/500:\n",
            "Train Loss: 2.1733, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2435, Validation Accuracy: 0.2817\n",
            "Epoch 338/500:\n",
            "Train Loss: 2.1864, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2364, Validation Accuracy: 0.2958\n",
            "Epoch 339/500:\n",
            "Train Loss: 2.1936, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2118, Validation Accuracy: 0.2817\n",
            "Epoch 340/500:\n",
            "Train Loss: 2.1890, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.2169, Validation Accuracy: 0.3099\n",
            "Epoch 341/500:\n",
            "Train Loss: 2.1790, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2080, Validation Accuracy: 0.2817\n",
            "Epoch 342/500:\n",
            "Train Loss: 2.1862, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.2128, Validation Accuracy: 0.2676\n",
            "Epoch 343/500:\n",
            "Train Loss: 2.1767, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2098, Validation Accuracy: 0.2958\n",
            "Epoch 344/500:\n",
            "Train Loss: 2.1746, Train Accuracy: 0.3194\n",
            "Validation Loss: 3.2011, Validation Accuracy: 0.2958\n",
            "Epoch 345/500:\n",
            "Train Loss: 2.1852, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1983, Validation Accuracy: 0.2958\n",
            "Epoch 346/500:\n",
            "Train Loss: 2.1785, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2004, Validation Accuracy: 0.2958\n",
            "Epoch 347/500:\n",
            "Train Loss: 2.1814, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.2057, Validation Accuracy: 0.2817\n",
            "Epoch 348/500:\n",
            "Train Loss: 2.1876, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2007, Validation Accuracy: 0.2676\n",
            "Epoch 349/500:\n",
            "Train Loss: 2.1758, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1979, Validation Accuracy: 0.2676\n",
            "Epoch 350/500:\n",
            "Train Loss: 2.1835, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2127, Validation Accuracy: 0.2676\n",
            "Epoch 351/500:\n",
            "Train Loss: 2.1826, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.2387, Validation Accuracy: 0.2817\n",
            "Epoch 352/500:\n",
            "Train Loss: 2.1826, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.2142, Validation Accuracy: 0.3099\n",
            "Epoch 353/500:\n",
            "Train Loss: 2.1914, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.1922, Validation Accuracy: 0.2958\n",
            "Epoch 354/500:\n",
            "Train Loss: 2.1742, Train Accuracy: 0.3176\n",
            "Validation Loss: 3.1772, Validation Accuracy: 0.2817\n",
            "Epoch 355/500:\n",
            "Train Loss: 2.2002, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.1615, Validation Accuracy: 0.2817\n",
            "Epoch 356/500:\n",
            "Train Loss: 2.1844, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.1543, Validation Accuracy: 0.2676\n",
            "Epoch 357/500:\n",
            "Train Loss: 2.1832, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.1680, Validation Accuracy: 0.2817\n",
            "Epoch 358/500:\n",
            "Train Loss: 2.1731, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.1644, Validation Accuracy: 0.2817\n",
            "Epoch 359/500:\n",
            "Train Loss: 2.1767, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1911, Validation Accuracy: 0.2817\n",
            "Epoch 360/500:\n",
            "Train Loss: 2.1887, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2153, Validation Accuracy: 0.2676\n",
            "Epoch 361/500:\n",
            "Train Loss: 2.1799, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.2128, Validation Accuracy: 0.2817\n",
            "Epoch 362/500:\n",
            "Train Loss: 2.1897, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1837, Validation Accuracy: 0.2817\n",
            "Epoch 363/500:\n",
            "Train Loss: 2.1824, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1754, Validation Accuracy: 0.2817\n",
            "Epoch 364/500:\n",
            "Train Loss: 2.1784, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2004, Validation Accuracy: 0.2676\n",
            "Epoch 365/500:\n",
            "Train Loss: 2.1806, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.1719, Validation Accuracy: 0.2676\n",
            "Epoch 366/500:\n",
            "Train Loss: 2.1937, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1624, Validation Accuracy: 0.2676\n",
            "Epoch 367/500:\n",
            "Train Loss: 2.1700, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.1387, Validation Accuracy: 0.2817\n",
            "Epoch 368/500:\n",
            "Train Loss: 2.1866, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1620, Validation Accuracy: 0.2817\n",
            "Epoch 369/500:\n",
            "Train Loss: 2.1776, Train Accuracy: 0.2949\n",
            "Validation Loss: 3.1755, Validation Accuracy: 0.2817\n",
            "Epoch 370/500:\n",
            "Train Loss: 2.1769, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.1666, Validation Accuracy: 0.3099\n",
            "Epoch 371/500:\n",
            "Train Loss: 2.1780, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.1598, Validation Accuracy: 0.2958\n",
            "Epoch 372/500:\n",
            "Train Loss: 2.1855, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1645, Validation Accuracy: 0.2958\n",
            "Epoch 373/500:\n",
            "Train Loss: 2.1871, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1756, Validation Accuracy: 0.2817\n",
            "Epoch 374/500:\n",
            "Train Loss: 2.1808, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.1562, Validation Accuracy: 0.2817\n",
            "Epoch 375/500:\n",
            "Train Loss: 2.1798, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.1901, Validation Accuracy: 0.2958\n",
            "Epoch 376/500:\n",
            "Train Loss: 2.1742, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.1788, Validation Accuracy: 0.3099\n",
            "Epoch 377/500:\n",
            "Train Loss: 2.1778, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.1725, Validation Accuracy: 0.2958\n",
            "Epoch 378/500:\n",
            "Train Loss: 2.1852, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.1610, Validation Accuracy: 0.2958\n",
            "Epoch 379/500:\n",
            "Train Loss: 2.1878, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1601, Validation Accuracy: 0.2958\n",
            "Epoch 380/500:\n",
            "Train Loss: 2.1827, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.1952, Validation Accuracy: 0.2676\n",
            "Epoch 381/500:\n",
            "Train Loss: 2.1776, Train Accuracy: 0.3176\n",
            "Validation Loss: 3.2203, Validation Accuracy: 0.3099\n",
            "Epoch 382/500:\n",
            "Train Loss: 2.1790, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2104, Validation Accuracy: 0.2817\n",
            "Epoch 383/500:\n",
            "Train Loss: 2.1754, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2100, Validation Accuracy: 0.2817\n",
            "Epoch 384/500:\n",
            "Train Loss: 2.1812, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.2024, Validation Accuracy: 0.2958\n",
            "Epoch 385/500:\n",
            "Train Loss: 2.1805, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.1956, Validation Accuracy: 0.2817\n",
            "Epoch 386/500:\n",
            "Train Loss: 2.1835, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1919, Validation Accuracy: 0.2676\n",
            "Epoch 387/500:\n",
            "Train Loss: 2.1775, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.2178, Validation Accuracy: 0.2676\n",
            "Epoch 388/500:\n",
            "Train Loss: 2.1812, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2459, Validation Accuracy: 0.2958\n",
            "Epoch 389/500:\n",
            "Train Loss: 2.1791, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2865, Validation Accuracy: 0.2817\n",
            "Epoch 390/500:\n",
            "Train Loss: 2.1840, Train Accuracy: 0.2949\n",
            "Validation Loss: 3.2444, Validation Accuracy: 0.2958\n",
            "Epoch 391/500:\n",
            "Train Loss: 2.1803, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.2167, Validation Accuracy: 0.2958\n",
            "Epoch 392/500:\n",
            "Train Loss: 2.1798, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2325, Validation Accuracy: 0.2676\n",
            "Epoch 393/500:\n",
            "Train Loss: 2.1801, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2472, Validation Accuracy: 0.2817\n",
            "Epoch 394/500:\n",
            "Train Loss: 2.1771, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2586, Validation Accuracy: 0.2676\n",
            "Epoch 395/500:\n",
            "Train Loss: 2.1761, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2506, Validation Accuracy: 0.2676\n",
            "Epoch 396/500:\n",
            "Train Loss: 2.1918, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.1906, Validation Accuracy: 0.2958\n",
            "Epoch 397/500:\n",
            "Train Loss: 2.1787, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.1897, Validation Accuracy: 0.2817\n",
            "Epoch 398/500:\n",
            "Train Loss: 2.1843, Train Accuracy: 0.2932\n",
            "Validation Loss: 3.1834, Validation Accuracy: 0.2958\n",
            "Epoch 399/500:\n",
            "Train Loss: 2.1817, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.2080, Validation Accuracy: 0.2958\n",
            "Epoch 400/500:\n",
            "Train Loss: 2.1756, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2299, Validation Accuracy: 0.2817\n",
            "Epoch 401/500:\n",
            "Train Loss: 2.1796, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2120, Validation Accuracy: 0.2958\n",
            "Epoch 402/500:\n",
            "Train Loss: 2.1798, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2165, Validation Accuracy: 0.2958\n",
            "Epoch 403/500:\n",
            "Train Loss: 2.1874, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2093, Validation Accuracy: 0.3099\n",
            "Epoch 404/500:\n",
            "Train Loss: 2.1825, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2241, Validation Accuracy: 0.2958\n",
            "Epoch 405/500:\n",
            "Train Loss: 2.1795, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2498, Validation Accuracy: 0.2817\n",
            "Epoch 406/500:\n",
            "Train Loss: 2.1783, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2289, Validation Accuracy: 0.3099\n",
            "Epoch 407/500:\n",
            "Train Loss: 2.1886, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2319, Validation Accuracy: 0.3099\n",
            "Epoch 408/500:\n",
            "Train Loss: 2.1739, Train Accuracy: 0.3281\n",
            "Validation Loss: 3.2269, Validation Accuracy: 0.3239\n",
            "Epoch 409/500:\n",
            "Train Loss: 2.1808, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2416, Validation Accuracy: 0.2958\n",
            "Epoch 410/500:\n",
            "Train Loss: 2.1796, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2371, Validation Accuracy: 0.2958\n",
            "Epoch 411/500:\n",
            "Train Loss: 2.1781, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2385, Validation Accuracy: 0.2817\n",
            "Epoch 412/500:\n",
            "Train Loss: 2.1722, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2570, Validation Accuracy: 0.3099\n",
            "Epoch 413/500:\n",
            "Train Loss: 2.1897, Train Accuracy: 0.2984\n",
            "Validation Loss: 3.2663, Validation Accuracy: 0.2958\n",
            "Epoch 414/500:\n",
            "Train Loss: 2.1769, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.2333, Validation Accuracy: 0.2817\n",
            "Epoch 415/500:\n",
            "Train Loss: 2.1741, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2275, Validation Accuracy: 0.2958\n",
            "Epoch 416/500:\n",
            "Train Loss: 2.1880, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2503, Validation Accuracy: 0.3099\n",
            "Epoch 417/500:\n",
            "Train Loss: 2.1870, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2234, Validation Accuracy: 0.3099\n",
            "Epoch 418/500:\n",
            "Train Loss: 2.1789, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2195, Validation Accuracy: 0.2817\n",
            "Epoch 419/500:\n",
            "Train Loss: 2.1830, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.2495, Validation Accuracy: 0.3099\n",
            "Epoch 420/500:\n",
            "Train Loss: 2.1852, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2359, Validation Accuracy: 0.2958\n",
            "Epoch 421/500:\n",
            "Train Loss: 2.1740, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2270, Validation Accuracy: 0.2958\n",
            "Epoch 422/500:\n",
            "Train Loss: 2.1822, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2200, Validation Accuracy: 0.3099\n",
            "Epoch 423/500:\n",
            "Train Loss: 2.1825, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2476, Validation Accuracy: 0.2817\n",
            "Epoch 424/500:\n",
            "Train Loss: 2.1887, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2481, Validation Accuracy: 0.3099\n",
            "Epoch 425/500:\n",
            "Train Loss: 2.1759, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.2382, Validation Accuracy: 0.2817\n",
            "Epoch 426/500:\n",
            "Train Loss: 2.1802, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2441, Validation Accuracy: 0.2676\n",
            "Epoch 427/500:\n",
            "Train Loss: 2.1806, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2277, Validation Accuracy: 0.2958\n",
            "Epoch 428/500:\n",
            "Train Loss: 2.1818, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2292, Validation Accuracy: 0.2817\n",
            "Epoch 429/500:\n",
            "Train Loss: 2.1811, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2245, Validation Accuracy: 0.2676\n",
            "Epoch 430/500:\n",
            "Train Loss: 2.1809, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.2330, Validation Accuracy: 0.3239\n",
            "Epoch 431/500:\n",
            "Train Loss: 2.1788, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2338, Validation Accuracy: 0.2958\n",
            "Epoch 432/500:\n",
            "Train Loss: 2.1828, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2519, Validation Accuracy: 0.3099\n",
            "Epoch 433/500:\n",
            "Train Loss: 2.1796, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2674, Validation Accuracy: 0.3099\n",
            "Epoch 434/500:\n",
            "Train Loss: 2.1850, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2723, Validation Accuracy: 0.2958\n",
            "Epoch 435/500:\n",
            "Train Loss: 2.1773, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2526, Validation Accuracy: 0.2958\n",
            "Epoch 436/500:\n",
            "Train Loss: 2.1756, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.2527, Validation Accuracy: 0.2817\n",
            "Epoch 437/500:\n",
            "Train Loss: 2.1862, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2553, Validation Accuracy: 0.3099\n",
            "Epoch 438/500:\n",
            "Train Loss: 2.1820, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2452, Validation Accuracy: 0.3099\n",
            "Epoch 439/500:\n",
            "Train Loss: 2.1829, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2262, Validation Accuracy: 0.3099\n",
            "Epoch 440/500:\n",
            "Train Loss: 2.1849, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2377, Validation Accuracy: 0.2817\n",
            "Epoch 441/500:\n",
            "Train Loss: 2.1870, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2456, Validation Accuracy: 0.3099\n",
            "Epoch 442/500:\n",
            "Train Loss: 2.1857, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2443, Validation Accuracy: 0.3239\n",
            "Epoch 443/500:\n",
            "Train Loss: 2.1776, Train Accuracy: 0.3194\n",
            "Validation Loss: 3.2815, Validation Accuracy: 0.3099\n",
            "Epoch 444/500:\n",
            "Train Loss: 2.1859, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.2521, Validation Accuracy: 0.3239\n",
            "Epoch 445/500:\n",
            "Train Loss: 2.1734, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2370, Validation Accuracy: 0.3099\n",
            "Epoch 446/500:\n",
            "Train Loss: 2.1820, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.2519, Validation Accuracy: 0.2958\n",
            "Epoch 447/500:\n",
            "Train Loss: 2.1772, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2360, Validation Accuracy: 0.3239\n",
            "Epoch 448/500:\n",
            "Train Loss: 2.1795, Train Accuracy: 0.2932\n",
            "Validation Loss: 3.2345, Validation Accuracy: 0.3099\n",
            "Epoch 449/500:\n",
            "Train Loss: 2.1805, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2364, Validation Accuracy: 0.2676\n",
            "Epoch 450/500:\n",
            "Train Loss: 2.1846, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2333, Validation Accuracy: 0.2676\n",
            "Epoch 451/500:\n",
            "Train Loss: 2.1710, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2431, Validation Accuracy: 0.2817\n",
            "Epoch 452/500:\n",
            "Train Loss: 2.1773, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2297, Validation Accuracy: 0.3099\n",
            "Epoch 453/500:\n",
            "Train Loss: 2.1774, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2504, Validation Accuracy: 0.3099\n",
            "Epoch 454/500:\n",
            "Train Loss: 2.1653, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2368, Validation Accuracy: 0.3099\n",
            "Epoch 455/500:\n",
            "Train Loss: 2.1828, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.2612, Validation Accuracy: 0.2817\n",
            "Epoch 456/500:\n",
            "Train Loss: 2.1739, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2468, Validation Accuracy: 0.2958\n",
            "Epoch 457/500:\n",
            "Train Loss: 2.1771, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2427, Validation Accuracy: 0.2958\n",
            "Epoch 458/500:\n",
            "Train Loss: 2.1790, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2678, Validation Accuracy: 0.2958\n",
            "Epoch 459/500:\n",
            "Train Loss: 2.1789, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.2910, Validation Accuracy: 0.2676\n",
            "Epoch 460/500:\n",
            "Train Loss: 2.1779, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.2520, Validation Accuracy: 0.2676\n",
            "Epoch 461/500:\n",
            "Train Loss: 2.1788, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.2550, Validation Accuracy: 0.3099\n",
            "Epoch 462/500:\n",
            "Train Loss: 2.1761, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2711, Validation Accuracy: 0.3099\n",
            "Epoch 463/500:\n",
            "Train Loss: 2.1731, Train Accuracy: 0.3141\n",
            "Validation Loss: 3.2879, Validation Accuracy: 0.2676\n",
            "Epoch 464/500:\n",
            "Train Loss: 2.1790, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2543, Validation Accuracy: 0.3099\n",
            "Epoch 465/500:\n",
            "Train Loss: 2.1899, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2599, Validation Accuracy: 0.2958\n",
            "Epoch 466/500:\n",
            "Train Loss: 2.1738, Train Accuracy: 0.2949\n",
            "Validation Loss: 3.2475, Validation Accuracy: 0.2958\n",
            "Epoch 467/500:\n",
            "Train Loss: 2.1771, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2687, Validation Accuracy: 0.2958\n",
            "Epoch 468/500:\n",
            "Train Loss: 2.1782, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.2386, Validation Accuracy: 0.2817\n",
            "Epoch 469/500:\n",
            "Train Loss: 2.1766, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2334, Validation Accuracy: 0.2817\n",
            "Epoch 470/500:\n",
            "Train Loss: 2.1772, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2386, Validation Accuracy: 0.2958\n",
            "Epoch 471/500:\n",
            "Train Loss: 2.1679, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2145, Validation Accuracy: 0.2817\n",
            "Epoch 472/500:\n",
            "Train Loss: 2.1704, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2453, Validation Accuracy: 0.2676\n",
            "Epoch 473/500:\n",
            "Train Loss: 2.1849, Train Accuracy: 0.3054\n",
            "Validation Loss: 3.2446, Validation Accuracy: 0.2817\n",
            "Epoch 474/500:\n",
            "Train Loss: 2.1817, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.2335, Validation Accuracy: 0.2676\n",
            "Epoch 475/500:\n",
            "Train Loss: 2.1868, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2425, Validation Accuracy: 0.3099\n",
            "Epoch 476/500:\n",
            "Train Loss: 2.1768, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.2311, Validation Accuracy: 0.2676\n",
            "Epoch 477/500:\n",
            "Train Loss: 2.1754, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2357, Validation Accuracy: 0.2958\n",
            "Epoch 478/500:\n",
            "Train Loss: 2.1832, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2363, Validation Accuracy: 0.2958\n",
            "Epoch 479/500:\n",
            "Train Loss: 2.1811, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2465, Validation Accuracy: 0.2676\n",
            "Epoch 480/500:\n",
            "Train Loss: 2.1837, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2314, Validation Accuracy: 0.2817\n",
            "Epoch 481/500:\n",
            "Train Loss: 2.1880, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.1975, Validation Accuracy: 0.2958\n",
            "Epoch 482/500:\n",
            "Train Loss: 2.1843, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2393, Validation Accuracy: 0.2817\n",
            "Epoch 483/500:\n",
            "Train Loss: 2.1746, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.2173, Validation Accuracy: 0.2958\n",
            "Epoch 484/500:\n",
            "Train Loss: 2.1802, Train Accuracy: 0.3124\n",
            "Validation Loss: 3.2212, Validation Accuracy: 0.2817\n",
            "Epoch 485/500:\n",
            "Train Loss: 2.1789, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2552, Validation Accuracy: 0.2958\n",
            "Epoch 486/500:\n",
            "Train Loss: 2.1891, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2443, Validation Accuracy: 0.2958\n",
            "Epoch 487/500:\n",
            "Train Loss: 2.1758, Train Accuracy: 0.2967\n",
            "Validation Loss: 3.2196, Validation Accuracy: 0.2817\n",
            "Epoch 488/500:\n",
            "Train Loss: 2.1828, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2156, Validation Accuracy: 0.2676\n",
            "Epoch 489/500:\n",
            "Train Loss: 2.1683, Train Accuracy: 0.3176\n",
            "Validation Loss: 3.2286, Validation Accuracy: 0.2958\n",
            "Epoch 490/500:\n",
            "Train Loss: 2.1737, Train Accuracy: 0.3159\n",
            "Validation Loss: 3.2718, Validation Accuracy: 0.2817\n",
            "Epoch 491/500:\n",
            "Train Loss: 2.1786, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2321, Validation Accuracy: 0.2958\n",
            "Epoch 492/500:\n",
            "Train Loss: 2.1818, Train Accuracy: 0.3037\n",
            "Validation Loss: 3.2236, Validation Accuracy: 0.2817\n",
            "Epoch 493/500:\n",
            "Train Loss: 2.1702, Train Accuracy: 0.3072\n",
            "Validation Loss: 3.2458, Validation Accuracy: 0.2676\n",
            "Epoch 494/500:\n",
            "Train Loss: 2.1776, Train Accuracy: 0.3019\n",
            "Validation Loss: 3.2405, Validation Accuracy: 0.2676\n",
            "Epoch 495/500:\n",
            "Train Loss: 2.1752, Train Accuracy: 0.3089\n",
            "Validation Loss: 3.2409, Validation Accuracy: 0.2676\n",
            "Epoch 496/500:\n",
            "Train Loss: 2.1792, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2611, Validation Accuracy: 0.2676\n",
            "Epoch 497/500:\n",
            "Train Loss: 2.1757, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2670, Validation Accuracy: 0.2817\n",
            "Epoch 498/500:\n",
            "Train Loss: 2.1808, Train Accuracy: 0.3002\n",
            "Validation Loss: 3.2975, Validation Accuracy: 0.2817\n",
            "Epoch 499/500:\n",
            "Train Loss: 2.1820, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2661, Validation Accuracy: 0.2676\n",
            "Epoch 500/500:\n",
            "Train Loss: 2.1819, Train Accuracy: 0.3106\n",
            "Validation Loss: 3.2662, Validation Accuracy: 0.2676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    test_loss = running_loss / len(dataloader)\n",
        "    test_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "# Test loop\n",
        "test_loss, test_accuracy = test(model, test_loader, criterion)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H0DFiuFyQs0",
        "outputId": "d39a98b6-b36e-4329-a9dd-696f1fb7011d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Test Loss: 2.8182, Test Accuracy: 0.2877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "            # Append the predicted labels to the predictions list\n",
        "            predictions.extend(predicted.tolist())\n",
        "\n",
        "    test_loss = running_loss / len(dataloader)\n",
        "    test_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    return test_loss, test_accuracy, predictions\n",
        "\n",
        "\n",
        "\n",
        "test_loss, test_accuracy, predictions = test(model, test_loader, criterion)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "print(\"Predictions:\")\n",
        "print(predictions[:batch_size])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRqKOdkczPRH",
        "outputId": "201fe917-62eb-4654-d56b-9f1c2b82a175"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Test Loss: 2.8182, Test Accuracy: 0.2877\n",
            "Predictions:\n",
            "[7, 29, 33, 3, 3, 3, 19, 18, 18, 29, 19, 33, 29, 29, 3, 29, 22, 33, 3, 3, 29, 14, 19, 29, 29, 3, 3, 33, 3, 8, 33, 3]\n"
          ]
        }
      ]
    }
  ]
}